---
phase: 06-polish-verification
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - clip_factory.py
  - live_session.py
  - push-to-talk.py
autonomous: true

must_haves:
  truths:
    - "Pre-recorded acknowledgment clips exist in audio/fillers/acknowledgment/"
    - "An acknowledgment clip plays before tool calls that take noticeable time (>300ms)"
    - "No acknowledgment plays if the tool call completes within 300ms"
    - "Tool intent is displayed in the overlay during tool use (e.g., 'Starting a task' not 'Using Tool')"
    - "Long tool chains (>4s) play nonverbal filler clips to indicate ongoing activity"
    - "Status file supports JSON metadata for richer overlay communication"
  artifacts:
    - path: "clip_factory.py"
      provides: "Acknowledgment clip generation with ACKNOWLEDGMENT_PROMPTS and ACK_CLIP_DIR"
      contains: "ACKNOWLEDGMENT_PROMPTS"
    - path: "live_session.py"
      provides: "Gated pre-tool acknowledgment, tool intent map, metadata-aware _set_status"
      contains: "TOOL_INTENT_MAP"
    - path: "push-to-talk.py"
      provides: "JSON-capable set_status function"
      contains: "json.dumps"
    - path: "audio/fillers/acknowledgment/"
      provides: "Pre-generated acknowledgment WAV clips"
  key_links:
    - from: "live_session.py"
      to: "push-to-talk.py"
      via: "_set_status('tool_use', metadata) -> on_status callback -> set_status writes JSON to STATUS_FILE"
      pattern: "TOOL_INTENT_MAP"
    - from: "clip_factory.py"
      to: "audio/fillers/acknowledgment/"
      via: "top_up_pool generates clips to ACK_CLIP_DIR"
      pattern: "ACK_CLIP_DIR"
    - from: "live_session.py"
      to: "audio/fillers/acknowledgment/"
      via: "_load_filler_clips loads acknowledgment clips at session start"
      pattern: "acknowledgment"
---

<objective>
Add pre-tool acknowledgment clips (verbal phrases like "let me check that"), extend the status system to carry tool intent metadata, and wire gated pre-tool playback into the CLI response handler.

Purpose: Tool-use waits feel dead without feedback. Acknowledgment clips provide instant verbal confirmation ("one sec"), tool intent metadata enables the overlay to show what the AI is doing, and long-chain fillers fill extended silences. This makes tool use feel natural rather than broken.

Output: Acknowledgment clip pool, gated pre-tool playback, tool intent map, JSON-capable status system.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-polish-verification/06-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend clip factory with acknowledgment category</name>
  <files>clip_factory.py</files>
  <action>
  Add a second clip category to clip_factory.py for verbal acknowledgment phrases. This reuses the existing generation and evaluation infrastructure with different prompts and directory.

  1. **Add constants** after the existing CLIP_DIR/POOL_META/PROMPTS block (around line 33):
  ```python
  ACK_CLIP_DIR = Path(__file__).parent / "audio" / "fillers" / "acknowledgment"
  ACK_POOL_META = Path(__file__).parent / "audio" / "fillers" / "ack_pool.json"
  ACK_POOL_SIZE_CAP = 15
  ACK_MIN_POOL_SIZE = 10

  ACKNOWLEDGMENT_PROMPTS = [
      "Let me check that.",
      "One sec.",
      "Sure, let me look.",
      "Let me see.",
      "Give me a moment.",
      "Checking now.",
      "On it.",
      "Looking into that.",
      "Let me find out.",
      "Just a moment.",
      "Hang on.",
      "Let me pull that up.",
      "Working on it.",
      "One moment.",
      "Let me take a look.",
  ]
  ```

  2. **Modify evaluate_clip** to accept an optional `category` parameter that adjusts quality thresholds. Acknowledgment clips are longer phrases so relax the duration ceiling:
  ```python
  def evaluate_clip(pcm_data: bytes, category: str = "nonverbal") -> dict:
      # ... existing calculation ...
      if category == "acknowledgment":
          passes = (
              0.3 <= duration <= 4.0  # Longer for full phrases
              and rms > 200           # Slightly lower — phrases may be quieter
              and clipping_ratio < 0.01
              and silence_ratio < 0.5  # Less silence tolerance
          )
      else:
          passes = (
              0.2 <= duration <= 2.0
              and rms > 300
              and clipping_ratio < 0.01
              and silence_ratio < 0.7
          )
      # ... rest unchanged ...
  ```

  3. **Add `top_up_ack_pool` function** that mirrors `top_up_pool` but uses ACK_CLIP_DIR, ACK_POOL_META, ACKNOWLEDGMENT_PROMPTS, and ACK_POOL_SIZE_CAP/ACK_MIN_POOL_SIZE. The synthesis params for acknowledgment clips should use tighter ranges for more natural speech:
  ```python
  def random_ack_params() -> dict:
      return {
          "prompt": random.choice(ACKNOWLEDGMENT_PROMPTS),
          "length_scale": round(random.uniform(0.9, 1.3), 2),  # Tighter for natural pace
          "noise_w_scale": round(random.uniform(0.3, 0.8), 2),
          "noise_scale": round(random.uniform(0.4, 0.7), 2),
      }
  ```

  4. **Update `top_up_pool`** signature to be reusable OR just call `top_up_ack_pool` from the main flow. Simplest: make top_up_pool accept parameters, or create a separate function. Since the logic is the same except for directory/prompts/thresholds, refactor into a generic `_top_up(clip_dir, pool_meta, min_size, cap, param_fn, category)` helper, then have `top_up_pool` and `top_up_ack_pool` call it. Keep the refactor minimal — if it gets complex, just duplicate the function with different constants.

  5. **Update daemon_mode and main** to also call top_up_ack_pool after top_up_pool.

  6. **Create the directory**: Ensure `ACK_CLIP_DIR.mkdir(parents=True, exist_ok=True)` is called at the start of top_up_ack_pool.

  Keep the existing nonverbal pool completely untouched — this adds a parallel pool, not a replacement.
  </action>
  <verify>
  Run `python clip_factory.py` to top up both pools. Verify it completes without error and creates files in `audio/fillers/acknowledgment/`.
  Run `ls audio/fillers/acknowledgment/*.wav | wc -l` to confirm clips were generated (should be >= ACK_MIN_POOL_SIZE).
  </verify>
  <done>clip_factory.py generates and manages a separate pool of 10-15 acknowledgment phrase clips in audio/fillers/acknowledgment/, with quality evaluation tuned for verbal phrases (0.3-4.0s duration, 200+ RMS).</done>
</task>

<task type="auto">
  <name>Task 2: Wire acknowledgment clips and tool intent into live session</name>
  <files>live_session.py, push-to-talk.py</files>
  <action>
  Three changes: (a) load acknowledgment clips at session start, (b) add gated pre-tool acknowledgment playback, (c) add tool intent map and metadata-aware status.

  **A. Load acknowledgment clips in _load_filler_clips** (around line 503):

  After the existing nonverbal loading block, add a second block that loads from `audio/fillers/acknowledgment/`:
  ```python
  ack_dir = Path(__file__).parent / "audio" / "fillers" / "acknowledgment"
  if ack_dir.exists():
      ack_clips = []
      for wav_path in sorted(ack_dir.glob("*.wav")):
          try:
              with wave.open(str(wav_path), 'rb') as wf:
                  pcm = wf.readframes(wf.getnframes())
                  rate = wf.getframerate()
              if rate != SAMPLE_RATE:
                  pcm = self._resample_22050_to_24000(pcm)
              ack_clips.append(pcm)
          except Exception as e:
              print(f"Live session: Error loading ack clip {wav_path}: {e}", flush=True)
      if ack_clips:
          self._filler_clips["acknowledgment"] = ack_clips
          self._last_filler["acknowledgment"] = -1
          print(f"Live session: Loaded {len(ack_clips)} acknowledgment clips", flush=True)
  ```

  The existing `_pick_filler` method already works with any category string, so no changes needed there.

  **B. Gated pre-tool acknowledgment in _read_cli_response** (around line 1074-1098):

  Replace the current first-tool-use block (which plays a nonverbal clip) with a gated acknowledgment system:

  ```python
  if content_block.get("type") == "tool_use":
      tool_name = content_block.get("name", "unknown")
      intent = TOOL_INTENT_MAP.get(tool_name, f"Using {tool_name.replace('_', ' ')}")

      if not saw_tool_use:
          saw_tool_use = True
          # Drain pre-tool frames (existing logic — keep as-is)
          drained = 0
          for q in (self._llm_out_q, self._audio_out_q):
              while not q.empty():
                  try:
                      f = q.get_nowait()
                      if f.type == FrameType.END_OF_TURN:
                          await q.put(f)
                          break
                      drained += 1
                  except asyncio.QueueEmpty:
                      break
          if drained:
              print(f"  [tool] Drained {drained} pre-tool frames", flush=True)

          # Play acknowledgment clip with 300ms gate
          if self.fillers_enabled:
              ack_cancel = asyncio.Event()
              self._ack_cancel = ack_cancel  # Store for cancellation if tool completes fast
              asyncio.create_task(
                  self._play_gated_ack(ack_cancel, gen_id)
              )
      else:
          # Subsequent tool calls in chain: play nonverbal filler for long chains
          # (handled by existing filler pattern — no change needed)
          pass

      # Update status with tool intent metadata
      self._set_status("tool_use", {"intent": intent})

      # Discard accumulated text (existing logic — keep as-is)
      if sentence_buffer.strip():
          print(f"  [tool] Suppressed text: \"{sentence_buffer.strip()[:60]}\"", flush=True)
          sentence_buffer = ""
      if post_tool_buffer.strip():
          print(f"  [tool] Suppressed inter-tool text: \"{post_tool_buffer.strip()[:60]}\"", flush=True)
          post_tool_buffer = ""
  ```

  **Add the `_play_gated_ack` method** to LiveSession:
  ```python
  async def _play_gated_ack(self, cancel_event: asyncio.Event, gen_id: int):
      """Play an acknowledgment clip after 300ms gate. Skip if cancelled (fast tool)."""
      try:
          await asyncio.wait_for(cancel_event.wait(), timeout=0.3)
          return  # Tool completed fast, skip acknowledgment
      except asyncio.TimeoutError:
          pass

      if cancel_event.is_set() or self.generation_id != gen_id:
          return

      # Try acknowledgment clip first, fall back to nonverbal
      clip = self._pick_filler("acknowledgment") or self._pick_filler("nonverbal")
      if clip:
          await self._play_filler_audio(clip, cancel_event)
  ```

  **Cancel acknowledgment on first text** — in the `content_block_delta` text_delta handler (around line 1128), after the existing filler cancel, also cancel the ack:
  ```python
  # Cancel filler on first text from LLM
  if self._filler_cancel and not self._filler_cancel.is_set():
      self._filler_cancel.set()
  # Cancel acknowledgment if still pending
  if hasattr(self, '_ack_cancel') and self._ack_cancel and not self._ack_cancel.is_set():
      self._ack_cancel.set()
  ```

  **Initialize `_ack_cancel`** in `__init__` alongside existing filler state:
  ```python
  self._ack_cancel = None
  ```

  **Add TOOL_INTENT_MAP** as a module-level constant near the top of live_session.py (after the existing constants, around line 37):
  ```python
  TOOL_INTENT_MAP = {
      "spawn_task": "Starting a task",
      "list_tasks": "Checking tasks",
      "get_task_status": "Checking task progress",
      "get_task_result": "Getting task results",
      "cancel_task": "Cancelling a task",
  }
  ```

  **C. Metadata-aware _set_status** (around line 472):

  Update `_set_status` to accept optional metadata and pass it through:
  ```python
  def _set_status(self, status, metadata=None):
      if metadata:
          self.on_status(status, metadata)
      else:
          self.on_status(status)
  ```

  But wait — the on_status callback is a simple `lambda s: None`. The callback chain goes: `self.on_status(status)` -> `set_status(status)` in push-to-talk.py -> `STATUS_FILE.write_text(status)`. We need to thread metadata through.

  Better approach: update `_set_status` to write metadata directly:
  ```python
  def _set_status(self, status, metadata=None):
      if metadata:
          import json
          self.on_status(json.dumps({"status": status, **metadata}))
      else:
          self.on_status(status)
  ```

  This way the on_status callback receives either a plain status string OR a JSON string. The set_status function in push-to-talk.py just writes whatever string it receives to STATUS_FILE — no changes needed there since it's already `STATUS_FILE.write_text(status)`.

  Actually, looking at push-to-talk.py `set_status` (line 451), it literally just does `STATUS_FILE.write_text(status)`. So the JSON string will be written as-is. The overlay's `check_status` will need to parse it (that's Plan 03). For now, just ensure the JSON string is written correctly.

  **No changes needed to push-to-talk.py** — the existing `set_status` passes through any string. The JSON detection happens in the overlay (Plan 03).

  **Long tool chain filler**: For chains exceeding ~4s, the existing `_filler_manager` pattern already handles subsequent filler clips. The acknowledgment plays once on first tool use. If tool use continues, the regular filler system kicks in. No additional code needed — the existing filler_manager is started when sending user text and cancelled on first LLM text. During tool use, the `_play_gated_ack` covers the initial wait.

  For very long chains (10+ seconds), add a tool-chain filler loop after the acknowledgment plays. Add to `_play_gated_ack`:
  ```python
  # If tool use continues for 4+ more seconds, play nonverbal fillers
  try:
      await asyncio.wait_for(cancel_event.wait(), timeout=4.0)
      return
  except asyncio.TimeoutError:
      pass

  if not cancel_event.is_set() and self.generation_id == gen_id:
      clip = self._pick_filler("nonverbal")
      if clip:
          await self._play_filler_audio(clip, cancel_event)
  ```
  </action>
  <verify>
  Run `python -c "import live_session; print('ok')"` to verify no syntax errors.
  Grep for `TOOL_INTENT_MAP` in live_session.py to confirm the map exists.
  Grep for `_play_gated_ack` in live_session.py to confirm the method exists.
  Grep for `acknowledgment` in live_session.py to confirm ack clip loading.
  </verify>
  <done>Acknowledgment clips load at session start, a gated (300ms) acknowledgment plays before the first tool call, tool intent metadata is extracted and passed through status, and long tool chains get nonverbal fillers after 4s.</done>
</task>

</tasks>

<verification>
1. `python -c "import live_session; print('ok')"` — no import errors
2. `python clip_factory.py` — generates acknowledgment clips without error
3. `ls audio/fillers/acknowledgment/*.wav` — clips exist
4. Grep confirms: TOOL_INTENT_MAP, _play_gated_ack, acknowledgment in live_session.py
5. Grep confirms: ACKNOWLEDGMENT_PROMPTS, ACK_CLIP_DIR in clip_factory.py
</verification>

<success_criteria>
- Acknowledgment clip pool exists with 10+ clips in audio/fillers/acknowledgment/
- First tool call triggers gated (300ms) acknowledgment clip playback
- Fast tool completions (<300ms) skip the acknowledgment
- TOOL_INTENT_MAP maps all 5 MCP tool names to human-readable intents
- Tool intent metadata is written to status file as JSON
- Long tool chains play nonverbal fillers after initial acknowledgment
- No regression in existing nonverbal filler system
</success_criteria>

<output>
After completion, create `.planning/phases/06-polish-verification/06-02-SUMMARY.md`
</output>
