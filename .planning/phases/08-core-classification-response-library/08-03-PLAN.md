---
phase: 08-core-classification-response-library
plan: 03
type: execute
wave: 3
depends_on: ["08-01", "08-02"]
files_modified:
  - live_session.py
autonomous: false

must_haves:
  truths:
    - "User says a question and hears a question-appropriate filler (not a task-oriented one)"
    - "User says a command and hears a task-appropriate filler (not a conversational one)"
    - "If classification fails or confidence is low, user hears a generic acknowledgment (never silence)"
    - "Classification completes within the existing 500ms filler gate with no perceptible added latency"
    - "Every classification is logged to the session JSONL with input_text, category, confidence, clip_id, clip_phrase"
    - "Seed library is generated in background on first launch; session falls back to existing ack pool until ready"
  artifacts:
    - path: "live_session.py"
      provides: "Pipeline integration of classifier daemon + response library into filler system"
      contains: "_classify_input|_spawn_classifier|ResponseLibrary"
  key_links:
    - from: "live_session.py"
      to: "input_classifier.py"
      via: "subprocess.Popen daemon spawn + Unix socket IPC"
      pattern: "input_classifier\\.py"
    - from: "live_session.py"
      to: "response_library.py"
      via: "ResponseLibrary import and load at session startup"
      pattern: "from response_library import"
    - from: "live_session.py _filler_manager"
      to: "live_session.py _classify_input"
      via: "Classification before clip selection"
      pattern: "_classify_input.*_filler_manager|_filler_manager.*_classify_input"
    - from: "live_session.py _filler_manager"
      to: "ResponseLibrary.lookup"
      via: "Category-aware clip selection replaces random _pick_filler"
      pattern: "_response_library\\.lookup"
---

<objective>
Wire the classifier daemon and response library into the live session pipeline, replacing the random acknowledgment filler system with context-aware clip selection.

Purpose: This is the integration plan that makes classification actually work end-to-end. Without this, the classifier and library are unused modules. After this plan, users hear contextually appropriate fillers.

Output: Modified live_session.py with classifier daemon lifecycle, IPC client, response library loading, rewritten _filler_manager, classification logging, and seed generation on first launch.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-core-classification-response-library/08-CONTEXT.md
@.planning/phases/08-core-classification-response-library/08-RESEARCH.md
@.planning/phases/08-core-classification-response-library/08-01-SUMMARY.md
@.planning/phases/08-core-classification-response-library/08-02-SUMMARY.md

Key source files:
@live_session.py (full file -- this is the file being modified)
@input_classifier.py (from Plan 01 -- daemon to spawn and communicate with)
@response_library.py (from Plan 01 -- library to load and query)
@clip_factory.py (from Plan 02 -- has generate_seed_responses for first-launch generation)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate classifier daemon + response library into live_session.py</name>
  <files>live_session.py</files>
  <action>
Modify live_session.py to wire in the classifier and response library. Changes organized by section:

**1. Imports (top of file):**
Add: `from response_library import ResponseLibrary`
(input_classifier.py is spawned as a subprocess, not imported)

**2. __init__ additions (after existing filler system block, around line 148):**
```python
# Response library (replaces random filler selection)
self._response_library = ResponseLibrary()
self._classifier_process = None
self._classifier_socket_path = None
```

**3. New method: `_spawn_classifier()`** (add near `_spawn_learner` and `_spawn_clip_factory`, around line 274):
Follow the `_spawn_learner()` pattern exactly, but with readiness signal:
```python
def _spawn_classifier(self):
    """Spawn the classifier daemon process."""
    self._classifier_socket_path = f"/tmp/ptt-classifier-{os.getpid()}.sock"
    if os.path.exists(self._classifier_socket_path):
        os.unlink(self._classifier_socket_path)

    classifier_script = Path(__file__).parent / "input_classifier.py"
    if not classifier_script.exists():
        print("Live session: input_classifier.py not found, skipping", flush=True)
        return

    cmd = [sys.executable, str(classifier_script), self._classifier_socket_path]
    try:
        self._classifier_process = subprocess.Popen(
            cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL,
            start_new_session=True
        )
        # Wait for readiness signal (up to 3 seconds)
        import select
        ready_fds, _, _ = select.select([self._classifier_process.stdout], [], [], 3.0)
        if ready_fds:
            line = self._classifier_process.stdout.readline().decode().strip()
            if "CLASSIFIER_READY" in line:
                print(f"Live session: Classifier spawned (PID {self._classifier_process.pid})", flush=True)
            else:
                print(f"Live session: Classifier unexpected output: {line}", flush=True)
        else:
            print("Live session: Classifier readiness timeout (3s), continuing", flush=True)
    except Exception as e:
        print(f"Live session: Failed to spawn classifier: {e}", flush=True)
        self._classifier_process = None
```

**4. New method: `_classify_input(text)`** (add near _spawn_classifier):
```python
async def _classify_input(self, text: str) -> dict:
    """Send text to classifier daemon, get classification result."""
    if not self._classifier_socket_path:
        return {"category": "acknowledgment", "confidence": 0.0}
    try:
        reader, writer = await asyncio.wait_for(
            asyncio.open_unix_connection(self._classifier_socket_path),
            timeout=0.1
        )
        request = json.dumps({"text": text}) + "\n"
        writer.write(request.encode())
        await writer.drain()
        response = await asyncio.wait_for(reader.readline(), timeout=0.1)
        writer.close()
        return json.loads(response.decode().strip())
    except Exception as e:
        print(f"  [classifier] IPC error: {e}", flush=True)
        return {"category": "acknowledgment", "confidence": 0.0}
```

**5. New method: `_load_response_library()`** (add near _load_filler_clips):
```python
def _load_response_library(self):
    """Load the categorized response library. Falls back to existing ack clips if not available."""
    self._response_library.load()
    if self._response_library.is_loaded():
        print(f"Live session: Response library loaded", flush=True)
    else:
        print("Live session: Response library empty, will use ack clip fallback", flush=True)
```

**6. New method: `_ensure_seed_library()`** (add near _spawn_clip_factory):
```python
def _ensure_seed_library(self):
    """Check if response library needs seed generation. Run in background if needed."""
    from response_library import LIBRARY_META
    if LIBRARY_META.exists():
        return  # Already seeded

    seed_phrases = Path(__file__).parent / "seed_phrases.json"
    if not seed_phrases.exists():
        return  # No seed phrases available

    factory_script = Path(__file__).parent / "clip_factory.py"
    if not factory_script.exists():
        return

    print("Live session: Seed library not found, generating in background...", flush=True)
    cmd = [sys.executable, str(factory_script), "--seed-responses"]
    try:
        self._seed_process = subprocess.Popen(
            cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL,
            start_new_session=True
        )
        print(f"Live session: Seed generation started (PID {self._seed_process.pid})", flush=True)
    except Exception as e:
        print(f"Live session: Failed to start seed generation: {e}", flush=True)
```

**7. Rewrite `_filler_manager()`** (replace existing around lines 559-574):
Replace the entire method with the classification-aware version from RESEARCH.md:
```python
async def _filler_manager(self, user_text: str, cancel_event: asyncio.Event):
    """Play a context-appropriate quick response while waiting for LLM."""
    # Step 1: Classify via daemon IPC (<5ms)
    classification = await self._classify_input(user_text)
    category = classification.get("category", "acknowledgment")
    confidence = classification.get("confidence", 0.0)
    subcategory = classification.get("subcategory", "")

    # Step 2: Low confidence -> fall back to acknowledgment
    if confidence < 0.4:
        category = "acknowledgment"

    # Step 3: Lookup clip from response library
    response = None
    clip_pcm = None
    if self._response_library.is_loaded():
        response = self._response_library.lookup(category, subcategory=subcategory)
        if response:
            clip_pcm = self._response_library.get_clip_pcm(response.id)

    # Step 4: Log classification trace
    self._log_event("classification",
        input_text=user_text,
        category=category,
        confidence=confidence,
        subcategory=subcategory,
        clip_id=response.id if response else None,
        clip_phrase=response.phrase if response else None,
        fallback_used=response is None,
    )

    # Step 5: Gate -- skip if LLM responds fast (500ms)
    try:
        await asyncio.wait_for(cancel_event.wait(), timeout=0.5)
        return
    except asyncio.TimeoutError:
        pass

    if cancel_event.is_set():
        return

    # Step 6: Play clip from response library
    if clip_pcm:
        clip_pcm = self._resample_22050_to_24000(clip_pcm)
        await self._play_filler_audio(clip_pcm, cancel_event)
        if response:
            barged = cancel_event.is_set()
            self._response_library.record_usage(response.id, barged_in=barged)
        return

    # Step 7: Ultimate fallback -- existing random ack clip (old system)
    clip = self._pick_filler("acknowledgment")
    if clip:
        await self._play_filler_audio(clip, cancel_event)
```

**8. Session startup modifications** (in the `start()` method, around lines 1900-1905):
After `self._spawn_clip_factory()` (line 1905), add:
```python
self._spawn_classifier()
self._ensure_seed_library()
self._load_response_library()
```

Also add `self._seed_process = None` to __init__.

**9. Session cleanup** (find the finally block or cleanup code at session end):
Add classifier cleanup near the existing learner/clip_factory cleanup:
```python
# Kill classifier daemon
if self._classifier_process:
    try:
        self._classifier_process.terminate()
        self._classifier_process.wait(timeout=3)
    except Exception:
        try:
            self._classifier_process.kill()
        except Exception:
            pass
if self._classifier_socket_path and os.path.exists(self._classifier_socket_path):
    try:
        os.unlink(self._classifier_socket_path)
    except Exception:
        pass

# Kill seed generation if still running
if hasattr(self, '_seed_process') and self._seed_process:
    try:
        self._seed_process.terminate()
    except Exception:
        pass

# Save response library usage data
if self._response_library.is_loaded():
    try:
        self._response_library.save()
    except Exception as e:
        print(f"Live session: Failed to save response library: {e}", flush=True)
```

**10. Hot-reload check** -- In the main pipeline loop or at the start of each `_filler_manager` call, check if the response library needs reloading (for when seed generation completes mid-session):
At the top of `_filler_manager`, before classification:
```python
# Hot-reload response library if seed generation completed
if not self._response_library.is_loaded():
    from response_library import LIBRARY_META
    if LIBRARY_META.exists():
        self._load_response_library()
```

**Key constraints:**
- Keep `_load_filler_clips()` and `_pick_filler()` UNTOUCHED -- they're the ultimate fallback (Step 7)
- The 500ms gate timing stays the same -- classification happens BEFORE the gate, not during
- Classification happens immediately when filler_manager starts (before the 500ms wait), so classification time is absorbed into the gate wait
- The `_resample_22050_to_24000` call on response library clips is necessary because Piper generates at 22050Hz but playback is 24000Hz
  </action>
  <verify>
Verify the code is syntactically correct:
```bash
cd /home/ethan/code/push-to-talk
python3 -c "
import live_session
ls = live_session.LiveSession.__dict__
assert '_classify_input' in ls, 'Missing _classify_input'
assert '_spawn_classifier' in ls, 'Missing _spawn_classifier'
assert '_load_response_library' in ls, 'Missing _load_response_library'
assert '_ensure_seed_library' in ls, 'Missing _ensure_seed_library'
print('All new methods present')
"
```

Verify imports work:
```bash
python3 -c "from response_library import ResponseLibrary; print('Import OK')"
```

Verify the _filler_manager signature accepts user_text and cancel_event:
```bash
python3 -c "
import inspect
from live_session import LiveSession
sig = inspect.signature(LiveSession._filler_manager)
params = list(sig.parameters.keys())
assert 'user_text' in params, f'Missing user_text param: {params}'
assert 'cancel_event' in params, f'Missing cancel_event param: {params}'
print(f'_filler_manager signature OK: {params}')
"
```
  </verify>
  <done>live_session.py spawns classifier daemon at session start, sends text for classification via Unix socket IPC, looks up category-appropriate clips from response library, falls back to existing ack pool when library is empty. Classification logging writes to session JSONL. Seed generation runs in background on first launch.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete classification + response library system: heuristic classifier daemon classifies user input into 6 categories, response library serves category-appropriate audio clips, pipeline plays contextual fillers instead of random acknowledgments.</what-built>
  <how-to-verify>
1. Start a live session (hold Right Ctrl + Right Shift)
2. Say a question like "What time is it?" or "How does this work?" -- listen for a question-appropriate filler ("Hmm.", "Good question.", "Let me think.")
3. Say a command like "Run the tests" or "Fix that bug" -- listen for a task-appropriate filler ("On it.", "Sure thing.", "Got it.")
4. Say "Hey!" -- listen for a social greeting filler ("Hey!", "Hi.")
5. Say something frustrated like "Ugh, that's terrible" -- listen for an emotional filler ("Ugh.", "That sucks.")
6. Say "Yeah" or "Ok" -- listen for an acknowledgment filler ("Gotcha.", "Sure.", "Right.")
7. Verify you NEVER hear silence where you used to hear a filler
8. Check the session log for classification entries:
   ```bash
   cat ~/Audio/push-to-talk/sessions/$(ls -t ~/Audio/push-to-talk/sessions/ | head -1)/conversation.jsonl | grep classification | python3 -m json.tool | head -40
   ```
9. Verify classifications look correct (questions classified as "question", commands as "task", etc.)
  </how-to-verify>
  <resume-signal>Type "approved" or describe any issues with classification accuracy, clip selection, timing, or audio quality</resume-signal>
</task>

</tasks>

<verification>
- Classifier daemon starts at session launch and responds to IPC within 100ms
- _filler_manager classifies input before the 500ms gate (classification time absorbed into wait)
- Questions get question clips, commands get task clips, greetings get social clips
- Low-confidence classifications fall back to acknowledgment (never wrong-category clips)
- Classification events logged to session JSONL with full trace data
- Seed generation runs in background if library.json doesn't exist
- Response library hot-reloads when seed generation completes
- Existing ack pool serves as ultimate fallback when response library is empty
- Classifier daemon and socket cleaned up at session end
- Usage metrics saved to library.json at session end
</verification>

<success_criteria>
- End-to-end: user speaks, classifier categorizes, response library picks appropriate clip, clip plays as filler
- No regression: if classifier or library fails, existing random ack filler still plays
- No added latency: classification + library lookup complete in <10ms, absorbed into 500ms gate
- Classification logging: every filler event has a classification trace in session JSONL
</success_criteria>

<output>
After completion, create `.planning/phases/08-core-classification-response-library/08-03-SUMMARY.md`
</output>
