---
phase: 08-core-classification-response-library
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - seed_phrases.json
  - clip_factory.py
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "A committed seed_phrases.json contains 5-8 phrases per category (6 categories, ~46 total) with chill assistant personality"
    - "Running the seed generator creates audio/responses/{category}/ directories with WAV clips and a valid library.json"
    - "Emotional phrases have subcategory annotations (frustration, excitement, gratitude, sadness, general)"
    - "Generated clips pass quality evaluation (duration 0.3-4s, RMS > 200, low clipping/silence)"
  artifacts:
    - path: "seed_phrases.json"
      provides: "Phrase list for all 6 categories with subcategory annotations"
      contains: "task.*question.*conversational.*social.*emotional.*acknowledgment"
    - path: "clip_factory.py"
      provides: "generate_seed_responses() function and --seed-responses CLI flag"
      exports: ["generate_seed_responses"]
    - path: "audio/responses/library.json"
      provides: "Generated library index after seed generation runs"
      contains: "entries"
  key_links:
    - from: "clip_factory.py"
      to: "seed_phrases.json"
      via: "JSON load of phrase list"
      pattern: "seed_phrases\\.json"
    - from: "clip_factory.py"
      to: "response_library.py"
      via: "Writes library.json in ResponseLibrary format"
      pattern: "library\\.json"
---

<objective>
Create the seed phrase list and add seed generation capability to clip_factory.py so the response library can be populated on first launch.

Purpose: Without seed clips, the response library is empty and the system falls back to random acknowledgments (no improvement over v1.1). Seed generation creates the initial 30-40 categorized clips that make classification useful from the first session.

Output: seed_phrases.json (committed), modified clip_factory.py with `generate_seed_responses()` function, and .gitignore update to track response WAVs.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-core-classification-response-library/08-CONTEXT.md
@.planning/phases/08-core-classification-response-library/08-RESEARCH.md
@.planning/phases/08-core-classification-response-library/08-01-SUMMARY.md

Key source files:
@clip_factory.py (full file -- add seed generation alongside existing ack pool logic)
@response_library.py (from Plan 01 -- must write library.json in this module's expected format)
@.gitignore (needs update for audio/responses/ WAV tracking)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create seed_phrases.json with categorized phrases</name>
  <files>seed_phrases.json</files>
  <action>
Create `seed_phrases.json` at the project root with the phrase list from RESEARCH.md, plus subcategory annotations for emotional clips. The structure should be:

```json
{
  "task": [
    "On it.",
    "Sure thing.",
    "Got it.",
    "Gotcha.",
    "Let me take a look.",
    "Working on it.",
    "One sec.",
    "Let me check."
  ],
  "question": [
    "Hmm.",
    "Good question.",
    "Let me think.",
    "Hmm, let me think about that.",
    "Oh, interesting.",
    "Let me see."
  ],
  "conversational": [
    "Hmm.",
    "Right.",
    "Well.",
    "Oh.",
    "Yeah.",
    "Huh."
  ],
  "social": [
    "Hey!",
    "Hey, what's up.",
    "Hi.",
    "See ya.",
    "Later.",
    "Of course.",
    "You bet.",
    "Anytime."
  ],
  "emotional": [
    "Ugh.",
    "Nice!",
    "Wow.",
    "Aw, thanks.",
    "Oh no.",
    "Hell yeah.",
    "That sucks.",
    "Ha."
  ],
  "acknowledgment": [
    "Gotcha.",
    "Sure.",
    "Mm-hm.",
    "Right.",
    "Okay.",
    "Got it.",
    "Yep.",
    "Alright."
  ],
  "_emotional_subcategories": {
    "frustration": ["Ugh.", "That sucks."],
    "excitement": ["Nice!", "Hell yeah."],
    "gratitude": ["Aw, thanks."],
    "sadness": ["Oh no."],
    "general": ["Wow.", "Ha."]
  },
  "_social_subcategories": {
    "greeting": ["Hey!", "Hey, what's up.", "Hi."],
    "farewell": ["See ya.", "Later."],
    "thanks": ["Of course.", "You bet.", "Anytime."]
  }
}
```

The `_emotional_subcategories` and `_social_subcategories` maps (prefixed with _ to indicate metadata, not categories) tell the seed generator which subcategory to assign to each phrase. All other categories have subcategory "".

Personality: chill assistant -- casual, relaxed, like a friend. No formal phrases like "absolutely", "certainly", "I'd be happy to".
  </action>
  <verify>
```bash
cd /home/ethan/code/push-to-talk
python3 -c "
import json
data = json.loads(open('seed_phrases.json').read())
categories = ['task', 'question', 'conversational', 'social', 'emotional', 'acknowledgment']
total = 0
for cat in categories:
    count = len(data[cat])
    assert 5 <= count <= 10, f'{cat} has {count} phrases (want 5-10)'
    total += count
    print(f'  {cat}: {count} phrases')
print(f'Total: {total} phrases')
assert 30 <= total <= 50, f'Total {total} outside 30-50 range'
assert '_emotional_subcategories' in data, 'Missing emotional subcategories'
assert '_social_subcategories' in data, 'Missing social subcategories'
print('seed_phrases.json valid')
"
```
  </verify>
  <done>seed_phrases.json exists with 5-8 phrases per category (~46 total), emotional subcategory annotations, social subcategory annotations, and chill assistant personality throughout.</done>
</task>

<task type="auto">
  <name>Task 2: Add seed generation to clip_factory.py and update .gitignore</name>
  <files>clip_factory.py, .gitignore</files>
  <action>
**Modify clip_factory.py** to add seed response generation alongside the existing ack pool logic:

1. Add imports at top: `from response_library import RESPONSES_DIR, LIBRARY_META, CATEGORIES` (only import constants, not the class -- avoid circular dependencies if any)

   Actually, to avoid any import coupling, just define the constants inline:
   ```python
   RESPONSES_DIR = Path(__file__).parent / "audio" / "responses"
   RESPONSES_META = RESPONSES_DIR / "library.json"
   ```

2. Add `SEED_PHRASES_PATH = Path(__file__).parent / "seed_phrases.json"`

3. Add `generate_seed_responses()` function that:
   - Loads seed_phrases.json
   - For each category in ["task", "question", "conversational", "social", "emotional", "acknowledgment"]:
     - Creates `RESPONSES_DIR / category /` directory
     - For each phrase in that category:
       - Generate a clip using `generate_clip(phrase, length_scale=1.0, noise_w=0.667, noise_scale=0.667)` -- use Piper DEFAULTS (no randomization, per RESEARCH pitfall 4 about audio quality mismatch)
       - Evaluate with `evaluate_clip(pcm)`
       - If pass: save with `save_clip_to(pcm, filename, cat_dir)` using `_next_filename(phrase, existing)`
       - Determine subcategory from `_emotional_subcategories` / `_social_subcategories` maps in seed_phrases.json
       - Build entry dict matching library.json schema: id, category, subcategory, phrase, filename, use_count=0, barge_in_count=0, last_used=0.0
   - Write library.json ATOMICALLY (temp file + os.rename):
     ```python
     meta = {"version": 1, "entries": entries}
     tmp = RESPONSES_META.with_suffix(".json.tmp")
     tmp.write_text(json.dumps(meta, indent=2) + "\n")
     os.rename(str(tmp), str(RESPONSES_META))
     ```
   - Print summary: "Seed generation: {N} clips across {M} categories"

4. Add `_infer_subcategory(category, phrase, seed_data)` helper:
   - For emotional: check _emotional_subcategories map
   - For social: check _social_subcategories map
   - For all others: return ""

5. Add `--seed-responses` CLI flag to the argparse in `main()`:
   ```python
   parser.add_argument("--seed-responses", action="store_true", help="Generate seed response library clips")
   ```
   In main, if `args.seed_responses`: call `generate_seed_responses()` and return.

6. Keep ALL existing ack pool code untouched. The seed generation is additive.

**Modify .gitignore** to include the new response WAV files (same pattern as existing ack fillers):
- Add `!audio/responses/**/*.wav` line after the existing `!audio/fillers/**/*.wav` line

Important: Use Piper defaults for seed generation (length_scale=1.0, noise_w=0.667, noise_scale=0.667) -- do NOT use the randomized `random_ack_params()`. This ensures seed clips match the voice quality of live TTS responses (per RESEARCH pitfall 4).
  </action>
  <verify>
First verify the code is syntactically correct and the flag exists:
```bash
cd /home/ethan/code/push-to-talk
python3 -c "from clip_factory import generate_seed_responses; print('Import OK')"
python3 clip_factory.py --help | grep -q 'seed-responses' && echo 'CLI flag present'
```

Then run the actual seed generation (this takes 45-90 seconds as it generates ~46 clips via Piper):
```bash
python3 clip_factory.py --seed-responses
```

Verify output:
```bash
python3 -c "
import json
from pathlib import Path
meta_path = Path('audio/responses/library.json')
assert meta_path.exists(), 'library.json not created'
meta = json.loads(meta_path.read_text())
assert meta.get('version') == 1, 'Wrong version'
entries = meta.get('entries', [])
print(f'Total entries: {len(entries)}')
cats = {}
for e in entries:
    cats[e['category']] = cats.get(e['category'], 0) + 1
for c, n in sorted(cats.items()):
    print(f'  {c}: {n} clips')
    wav_dir = Path('audio/responses') / c
    wavs = list(wav_dir.glob('*.wav'))
    assert len(wavs) >= n, f'{c}: {len(wavs)} WAVs but {n} entries'
assert len(entries) >= 30, f'Only {len(entries)} clips (need >= 30)'
# Verify subcategories on emotional clips
emotional = [e for e in entries if e['category'] == 'emotional']
subcats = {e['subcategory'] for e in emotional}
assert len(subcats) >= 3, f'Emotional only has subcategories: {subcats}'
print('Seed generation verified')
"
```

Verify .gitignore:
```bash
grep -q 'audio/responses' .gitignore && echo '.gitignore updated'
```
  </verify>
  <done>Seed generation produces 30+ WAV clips across 6 categories with correct subcategory annotations. library.json is written atomically. .gitignore tracks response WAV files. Existing ack pool code unchanged.</done>
</task>

</tasks>

<verification>
- seed_phrases.json committed with 46 phrases across 6 categories
- `python3 clip_factory.py --seed-responses` generates clips into audio/responses/{category}/
- library.json contains 30+ entries with version, id, category, subcategory, phrase, filename, metrics
- WAV files exist on disk matching library.json entries
- Emotional clips have subcategory annotations (frustration, excitement, gratitude, sadness, general)
- Social clips have subcategory annotations (greeting, farewell, thanks)
- Existing `python3 clip_factory.py` (ack pool top-up) still works unchanged
- .gitignore includes audio/responses/ WAV files
</verification>

<success_criteria>
- seed_phrases.json contains 30-50 phrases with chill assistant personality across all 6 categories
- clip_factory.py generates seed clips using Piper defaults (matching live TTS quality)
- library.json written atomically with correct schema
- 30+ clips generated and pass quality evaluation
- Emotional and social subcategories properly assigned
</success_criteria>

<output>
After completion, create `.planning/phases/08-core-classification-response-library/08-02-SUMMARY.md`
</output>
