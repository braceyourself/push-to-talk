---
phase: 08-core-classification-response-library
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - input_classifier.py
  - response_library.py
autonomous: true

must_haves:
  truths:
    - "Classifier daemon starts, listens on a Unix socket, and returns category+confidence JSON for any input text"
    - "Response library loads clips from audio/responses/ directories and picks category-appropriate clips with no-repeat guard"
    - "Both modules can be imported and tested independently before pipeline integration"
  artifacts:
    - path: "input_classifier.py"
      provides: "Standalone classifier daemon with Unix socket IPC server"
      exports: ["classify", "ClassifiedInput", "main"]
    - path: "response_library.py"
      provides: "ResponseLibrary class for loading/querying categorized clips"
      exports: ["ResponseLibrary", "ResponseEntry"]
  key_links:
    - from: "input_classifier.py"
      to: "asyncio.start_unix_server"
      via: "Unix socket server accepting JSON-line requests"
      pattern: "start_unix_server"
    - from: "response_library.py"
      to: "audio/responses/library.json"
      via: "JSON metadata load at startup"
      pattern: "library\\.json"
---

<objective>
Create the two core modules for the classification + response library system: `input_classifier.py` (daemon that classifies user input via heuristic pattern matching) and `response_library.py` (data structure that stores/queries categorized audio clips).

Purpose: These are the foundation that seed generation (Plan 02) and pipeline integration (Plan 03) build on. The classifier must be a standalone daemon process. The response library must manage per-category clip pools with usage tracking.

Output: Two new Python files that can be tested independently.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-core-classification-response-library/08-CONTEXT.md
@.planning/phases/08-core-classification-response-library/08-RESEARCH.md

Key source files to reference:
@live_session.py (lines 862-896 for _start_tool_ipc_server Unix socket pattern)
@live_session.py (lines 516-557 for _load_filler_clips and _pick_filler patterns)
@live_session.py (lines 243-273 for _spawn_learner and _spawn_clip_factory daemon patterns)
@clip_factory.py (for generate_clip, evaluate_clip, save_clip_to, _next_filename, _load_meta, _save_meta functions)
@pipeline_frames.py (for existing dataclass pattern)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create input_classifier.py -- heuristic classifier daemon</name>
  <files>input_classifier.py</files>
  <action>
Create `input_classifier.py` as a standalone daemon script that:

1. **ClassifiedInput dataclass** with fields: `category` (str), `confidence` (float 0-1), `original_text` (str), `subcategory` (str, default ""). Categories are: "task", "question", "conversational", "social", "emotional", "acknowledgment".

2. **Compiled regex patterns** (PATTERNS dict) for each category. Follow the patterns from RESEARCH.md Pattern 1 exactly. Key patterns:
   - question: starts with question words (what/how/why/when/where/who/which/can/could/would/should/is/are/do/does/did/will/has/have/was/were), ends with ?
   - task: starts with imperatives (please/can you/could you/would you/go ahead/just/try), contains action verbs (run/check/find/fix/build/deploy/create/update/delete/refactor/test/look at/pull up/open/close/restart/install/show me)
   - social: greetings (hey/hi/hello/howdy/yo/sup), farewells (bye/goodbye/see you/later/take care), thanks (thanks/thank you/appreciate/cheers)
   - emotional: frustration (ugh/damn/crap/shit/fuck/dammit/argh), excitement (awesome/amazing/incredible/nice/sick/hell yeah), gratitude (thank you so much/really appreciate/you're the best), negativity (sucks/terrible/horrible/frustrated/hate)
   - acknowledgment: short affirmatives (yes/yeah/yep/yup/ok/okay/sure/got it/right/exactly/mhm/alright/cool), negatives (no/nah/nope)
   - conversational: no specific patterns -- this is the "none of the above" for longer non-task statements

3. **`classify(text)` function** implementing:
   - Short text (<=3 words, no ?) checks acknowledgment patterns first (0.9 confidence)
   - Score each category by counting regex matches
   - Best category gets confidence = min(0.5 + matches * 0.2, 0.95)
   - Structural fallback: ends with ? -> question (0.6 confidence)
   - Ultimate default: "acknowledgment" (0.3 confidence) -- NOT "task", because acknowledgment is the safest fallback per CONTEXT.md
   - Subcategory inference for social (greeting vs farewell) and emotional (frustration, excitement, gratitude, sadness)

4. **Unix socket server** using `asyncio.start_unix_server` (match the `_start_tool_ipc_server` pattern from live_session.py lines 862-896):
   - `handle_client(reader, writer)`: read one JSON line, call classify, write JSON response line
   - `run_server(socket_path)`: start server, print "CLASSIFIER_READY" to stdout (readiness signal), serve_forever
   - `main()`: parse socket_path from sys.argv[1], run server
   - On error: return `{"category": "acknowledgment", "confidence": 0.0, "error": "..."}` (safe fallback)
   - 5s timeout on client reads

Important: Use `re.IGNORECASE` flag on all patterns. The default fallback must be "acknowledgment" (not "task") because acknowledgment is safe for any input -- a wrong-category clip is worse than a generic one.
  </action>
  <verify>
Run the classifier manually to verify it works:
```bash
cd /home/ethan/code/push-to-talk
python3 -c "
from input_classifier import classify, ClassifiedInput
# Test question
r = classify('What time is it?')
assert r.category == 'question', f'Expected question, got {r.category}'
# Test task
r = classify('Please run the tests')
assert r.category == 'task', f'Expected task, got {r.category}'
# Test social greeting
r = classify('Hey!')
assert r.category == 'social', f'Expected social, got {r.category}'
# Test emotional
r = classify('Ugh, that sucks')
assert r.category == 'emotional', f'Expected emotional, got {r.category}'
# Test acknowledgment
r = classify('Yeah')
assert r.category == 'acknowledgment', f'Expected acknowledgment, got {r.category}'
# Test fallback
r = classify('The weather is nice today')
assert r.confidence <= 0.5, f'Ambiguous text should have low confidence, got {r.confidence}'
print('All classification tests passed')
"
```
Also verify the daemon starts and responds:
```bash
python3 -c "
import asyncio, json, os, subprocess, sys, time
sock = '/tmp/ptt-test-classifier.sock'
if os.path.exists(sock): os.unlink(sock)
proc = subprocess.Popen([sys.executable, 'input_classifier.py', sock], stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
line = proc.stdout.readline().decode()
assert 'CLASSIFIER_READY' in line, f'No readiness signal: {line}'
async def test():
    r, w = await asyncio.open_unix_connection(sock)
    w.write(json.dumps({'text': 'fix the bug'}).encode() + b'\n')
    await w.drain()
    resp = await asyncio.wait_for(r.readline(), timeout=1.0)
    result = json.loads(resp.decode())
    assert result['category'] == 'task', f'Expected task, got {result}'
    w.close()
    print('Daemon IPC test passed')
asyncio.run(test())
proc.terminate()
os.unlink(sock)
"
```
  </verify>
  <done>input_classifier.py exists with classify() function and Unix socket daemon. Heuristic patterns correctly classify questions, tasks, social, emotional, and acknowledgment inputs. Daemon starts, signals readiness, and responds to JSON-line requests over Unix socket.</done>
</task>

<task type="auto">
  <name>Task 2: Create response_library.py -- categorized clip library</name>
  <files>response_library.py</files>
  <action>
Create `response_library.py` with:

1. **ResponseEntry dataclass** with fields:
   - `id` (str): unique identifier like "task_on_it_001"
   - `category` (str): one of the 6 categories
   - `subcategory` (str): e.g., "greeting", "farewell", "frustration", "excitement", "gratitude", "sadness", "" for none
   - `phrase` (str): the spoken text
   - `filename` (str): WAV filename within category directory
   - `use_count` (int, default 0): times this clip has been played
   - `barge_in_count` (int, default 0): times user interrupted this clip
   - `last_used` (float, default 0.0): timestamp of last use

2. **Module-level constants:**
   - `RESPONSES_DIR = Path(__file__).parent / "audio" / "responses"`
   - `LIBRARY_META = RESPONSES_DIR / "library.json"`
   - `CATEGORIES = ["task", "question", "conversational", "social", "emotional", "acknowledgment"]`

3. **ResponseLibrary class** with:
   - `__init__()`: initialize `_entries: list[ResponseEntry]`, `_index: dict[str, list[ResponseEntry]]` (category -> entries), `_clips: dict[str, bytes]` (entry_id -> pcm_bytes), `_recent: dict[str, deque]` (category -> recent IDs for no-repeat), `_loaded: bool` flag
   - `load()`: Read library.json, create ResponseEntry objects, build _index, load WAV files as raw PCM bytes from `RESPONSES_DIR / entry.category / entry.filename`. Handle missing files gracefully (skip entry, print warning). Use `wave` stdlib for reading.
   - `is_loaded() -> bool`: return whether library has any clips loaded
   - `lookup(category, subcategory="") -> ResponseEntry | None`:
     - Get candidates from _index[category]
     - If no candidates and category != "acknowledgment", fallback to _index["acknowledgment"]
     - If subcategory specified, prefer sub-matches but fall back to all category candidates
     - For emotional category: if subcategory has few entries (<= 2), include all emotional clips as candidates (avoids deterministic alternation per RESEARCH pitfall 6)
     - No-repeat guard using deque(maxlen=len(candidates)-1). If all recently used, reset.
     - Return random.choice from available candidates
   - `get_clip_pcm(entry_id) -> bytes | None`: return cached PCM bytes
   - `record_usage(entry_id, barged_in=False)`: increment use_count (and barge_in_count if barged_in), update last_used timestamp on the entry
   - `save()`: Atomic write of library.json -- write to .json.tmp then os.rename() (per RESEARCH pitfall 5). Serialize all entries back to JSON.
   - `reload()`: Re-run load() to pick up new clips (for hot-reload after seed generation). Clear and rebuild _clips and _index.

The library.json schema:
```json
{
  "version": 1,
  "entries": [
    {
      "id": "task_on_it_001",
      "category": "task",
      "subcategory": "",
      "phrase": "On it.",
      "filename": "on_it_001.wav",
      "use_count": 0,
      "barge_in_count": 0,
      "last_used": 0.0
    }
  ]
}
```

Important: Do NOT import from live_session.py. This module must be self-contained for import by both live_session.py and clip_factory.py.
  </action>
  <verify>
```bash
cd /home/ethan/code/push-to-talk
python3 -c "
from response_library import ResponseLibrary, ResponseEntry, RESPONSES_DIR, LIBRARY_META, CATEGORIES
# Verify classes exist and are importable
lib = ResponseLibrary()
assert not lib.is_loaded(), 'Should not be loaded with no files'
lib.load()  # Should handle missing library.json gracefully
assert not lib.is_loaded(), 'Should still not be loaded (no library.json)'
# Verify lookup returns None when empty
result = lib.lookup('task')
assert result is None, f'Expected None, got {result}'
# Verify categories constant
assert len(CATEGORIES) == 6, f'Expected 6 categories, got {len(CATEGORIES)}'
print('ResponseLibrary tests passed')
"
```
  </verify>
  <done>response_library.py exists with ResponseEntry dataclass and ResponseLibrary class. Library loads from JSON, queries by category with no-repeat guard, tracks usage metrics, supports atomic save and hot-reload. Handles missing files and empty state gracefully.</done>
</task>

</tasks>

<verification>
- Both files import cleanly: `python3 -c "import input_classifier; import response_library"`
- Classifier correctly categorizes 5 input types (question, task, social, emotional, acknowledgment)
- Classifier daemon starts on Unix socket and responds to JSON-line requests
- ResponseLibrary handles empty state (no library.json) without errors
- ResponseLibrary lookup falls back to acknowledgment when category has no clips
- No new dependencies required -- all stdlib
</verification>

<success_criteria>
- input_classifier.py classifies user text into 6 categories via regex heuristics in <1ms
- input_classifier.py runs as a daemon listening on a Unix socket, signaling readiness on stdout
- response_library.py loads/queries a categorized clip library from JSON + WAV files
- Both modules are self-contained (no cross-imports, no live_session.py dependency)
</success_criteria>

<output>
After completion, create `.planning/phases/08-core-classification-response-library/08-01-SUMMARY.md`
</output>
