---
phase: 04-filler-system-overhaul
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - live_session.py
  - personality/context.md
  - generate_fillers.py
  - audio/fillers/acknowledge/
  - audio/fillers/thinking/
  - audio/fillers/tool_use/
autonomous: true

must_haves:
  truths:
    - "No Ollama/LLM-generated filler text is spoken during live sessions"
    - "Fillers are exclusively non-verbal audio clips loaded from audio/fillers/nonverbal/"
    - "The clip factory daemon is spawned at session start (same pattern as learner daemon)"
    - "The personality prompt no longer references verbal acknowledgments"
    - "The _spoken_filler dedup logic is removed (non-verbal clips have no text to dedup)"
    - "Old verbal clip directories and generate_fillers.py are removed"
  artifacts:
    - path: "live_session.py"
      provides: "Simplified filler system using only non-verbal clips, clip factory spawn"
      contains: "_spawn_clip_factory"
    - path: "personality/context.md"
      provides: "Updated personality prompt without verbal filler references"
  key_links:
    - from: "live_session.py"
      to: "clip_factory.py"
      via: "subprocess.Popen spawn at session start"
      pattern: "subprocess\\.Popen.*clip_factory"
    - from: "live_session.py _load_filler_clips"
      to: "audio/fillers/nonverbal/"
      via: "glob WAV files from nonverbal directory"
      pattern: "nonverbal.*glob.*wav"
    - from: "live_session.py _filler_manager"
      to: "live_session.py _pick_filler"
      via: "picks from 'nonverbal' category only"
      pattern: "_pick_filler.*nonverbal"
---

<objective>
Remove the Ollama smart filler system from live_session.py and replace it with non-verbal clip-only fillers loaded from the pool created by Plan 01. Wire the clip factory daemon to spawn at session start. Clean up all deprecated filler code and files.

Purpose: This is the core behavioral change — the live session will no longer generate or speak any verbal filler text. All fillers become non-verbal audio clips (hums, breaths), eliminating the conflict where filler words duplicate the LLM's first sentence.

Output: A cleaner live_session.py with simplified filler logic, clip factory integration, updated personality prompt, and removal of deprecated files.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-filler-system-overhaul/04-RESEARCH.md
@.planning/phases/04-filler-system-overhaul/04-01-SUMMARY.md

Key source files to modify:
- @live_session.py (filler system overhaul — lines 34-35, 100, 128-134, 476-608, 1136-1141, 1182-1190, 1480-1486)
- @personality/context.md (line 37 — verbal filler reference)

Key source files to delete:
- @generate_fillers.py (OpenAI TTS-based verbal clip generator — fully replaced by clip_factory.py)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Remove smart filler code and simplify filler system in live_session.py</name>
  <files>live_session.py</files>
  <action>
Make these specific changes to live_session.py:

**Remove module-level constants (lines 34-35):**
- Delete `FILLER_TOOL_KEYWORDS = {...}`
- Delete `FILLER_THINKING_KEYWORDS = {...}`

**Remove instance variable (line 100):**
- Delete `self._spoken_filler = None` from `__init__`

**Update `_load_filler_clips()` (lines 476-509):**
Replace the entire method. Instead of loading from `("acknowledge", "thinking", "tool_use")` subdirectories, load from a single `"nonverbal"` subdirectory:

```python
def _load_filler_clips(self):
    """Load non-verbal filler WAV files as raw PCM bytes."""
    filler_dir = Path(__file__).parent / "audio" / "fillers" / "nonverbal"
    if not filler_dir.exists():
        print("Live session: No nonverbal filler directory found, fillers disabled", flush=True)
        self.fillers_enabled = False
        return

    clips = []
    for wav_path in sorted(filler_dir.glob("*.wav")):
        try:
            with wave.open(str(wav_path), 'rb') as wf:
                pcm = wf.readframes(wf.getnframes())
                rate = wf.getframerate()
            if rate != SAMPLE_RATE:
                pcm = self._resample_22050_to_24000(pcm)
            clips.append(pcm)
        except Exception as e:
            print(f"Live session: Error loading filler {wav_path}: {e}", flush=True)

    if clips:
        self._filler_clips["nonverbal"] = clips
        self._last_filler["nonverbal"] = -1
        print(f"Live session: Loaded {len(clips)} non-verbal filler clips", flush=True)
    else:
        print("Live session: No filler clips loaded, fillers disabled", flush=True)
        self.fillers_enabled = False
```

**Remove `_classify_filler_category()` (lines 525-532):**
Delete the entire method — no longer needed with single category.

**Replace `_filler_manager()` (lines 534-574):**
Replace with simplified non-verbal-only version:

```python
async def _filler_manager(self, user_text: str, cancel_event: asyncio.Event):
    """Play a non-verbal filler clip while waiting for LLM response."""
    # Stage 1: Wait 300ms gate — skip filler if LLM responds fast
    try:
        await asyncio.wait_for(cancel_event.wait(), timeout=0.3)
        return
    except asyncio.TimeoutError:
        pass

    if cancel_event.is_set():
        return

    # Play a non-verbal clip
    clip = self._pick_filler("nonverbal")
    if clip:
        await self._play_filler_audio(clip, cancel_event)

    # Stage 2: If still waiting after 4s, play another clip
    try:
        await asyncio.wait_for(cancel_event.wait(), timeout=4.0)
        return
    except asyncio.TimeoutError:
        pass

    if not cancel_event.is_set():
        clip = self._pick_filler("nonverbal")
        if clip:
            await self._play_filler_audio(clip, cancel_event)
```

**Remove `_generate_smart_filler()` (lines 576-608):**
Delete the entire method. This removes the Ollama dependency and the `aiohttp` import.

**Update tool_use filler in _read_cli_response (around line 1136-1141):**
Change `self._pick_filler("tool_use")` to `self._pick_filler("nonverbal")`.

**Remove filler dedup logic (around lines 1182-1190):**
Remove the block that checks `self._spoken_filler` and skips duplicate sentences. The code currently reads:
```python
if self._spoken_filler:
    filler_lower = self._spoken_filler.lower().rstrip('.!').strip()
    sent_lower = sentence.lower().rstrip('.!').strip()
    self._spoken_filler = None
    if filler_lower in sent_lower or sent_lower in filler_lower:
        print(f"  [filler] Skipped duplicate: \"{sentence}\"", flush=True)
        continue
```
Delete this entire block. Non-verbal clips have no text to duplicate.

**Remove `self._spoken_filler = None` reset (around line 1482):**
Remove this line from the transcript processing section.

**Add `_spawn_clip_factory()` method** (next to `_spawn_learner`, around line 237):
```python
def _spawn_clip_factory(self):
    """Spawn the clip factory to top up the non-verbal filler pool."""
    factory_script = Path(__file__).parent / "clip_factory.py"
    if not factory_script.exists():
        print("Live session: clip_factory.py not found, skipping", flush=True)
        return
    cmd = [sys.executable, str(factory_script)]
    try:
        self._clip_factory_process = subprocess.Popen(
            cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL,
            start_new_session=True
        )
        print(f"Live session: Clip factory spawned (PID {self._clip_factory_process.pid})", flush=True)
    except Exception as e:
        print(f"Live session: Failed to spawn clip factory: {e}", flush=True)
```

**Add `self._clip_factory_process = None` to `__init__`** (near the learner process init, around line 126).

**Call `_spawn_clip_factory()` at session start** — find where `_spawn_learner()` is called and add `self._spawn_clip_factory()` right after it. The learner is spawned in the `start()` or session setup method.

**Add clip factory cleanup at session end** — find where `self._learner_process` is cleaned up (terminated/killed) and add matching cleanup for `self._clip_factory_process`. Use the same pattern: check if process exists, poll, terminate if still running.

Important: Do NOT remove `_pick_filler()` or `_play_filler_audio()` — these are reused unchanged. Do NOT remove the `_tts_to_pcm()` method — it is used for main TTS, not just fillers.
  </action>
  <verify>
1. `grep -n "aiohttp\|_generate_smart_filler\|_spoken_filler\|_classify_filler_category\|FILLER_TOOL_KEYWORDS\|FILLER_THINKING_KEYWORDS" live_session.py` should return NO results.
2. `grep -n "_pick_filler\|_play_filler_audio\|_filler_manager\|_load_filler_clips\|_spawn_clip_factory\|nonverbal" live_session.py` should show the new simplified methods.
3. `python -c "import live_session; print('Import OK')"` should succeed without import errors.
  </verify>
  <done>
live_session.py has no Ollama smart filler code, no aiohttp import, no verbal filler categories, no filler text dedup logic. Filler system loads from nonverbal/ directory only. Clip factory spawns at session start. All removed code is gone, all retained code (pick_filler, play_filler_audio, tts_to_pcm) still works.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update personality prompt and clean up deprecated files</name>
  <files>personality/context.md, generate_fillers.py, audio/fillers/acknowledge/, audio/fillers/thinking/, audio/fillers/tool_use/</files>
  <action>
**Update personality/context.md line 37:**

Current text:
```
Brief acknowledgments like "Got it" or "Sure thing" are spoken automatically while you process. Never start your response with a greeting, acknowledgment, or filler phrase.
```

Replace with:
```
Non-verbal sounds like hums and breaths are played automatically while you process. Never start your response with a greeting, acknowledgment, or filler phrase like "Got it" or "Sure thing" — those would duplicate what's already been played.
```

**Delete generate_fillers.py:**
Remove the file entirely. It used OpenAI TTS to generate verbal clips — fully replaced by clip_factory.py.

```bash
rm generate_fillers.py
```

**Delete old verbal clip directories:**
```bash
rm -rf audio/fillers/acknowledge/
rm -rf audio/fillers/thinking/
rm -rf audio/fillers/tool_use/
```

These directories contain verbal clips ("Got it", "Right", "Let me think", etc.) that are no longer used. The nonverbal/ directory (created by Plan 01) is the only filler source now.

**Verify the audio/fillers/ directory structure is clean:**
After cleanup, `audio/fillers/` should contain only:
- `nonverbal/` (directory with WAV clips)
- `pool.json` (metadata file)
  </action>
  <verify>
1. `grep "Got it.*Sure thing\|Brief acknowledgments" personality/context.md` returns no results (old text gone)
2. `grep "Non-verbal sounds" personality/context.md` returns the new text
3. `test -f generate_fillers.py && echo "FAIL: still exists" || echo "OK: deleted"`
4. `test -d audio/fillers/acknowledge && echo "FAIL" || echo "OK"`
5. `test -d audio/fillers/thinking && echo "FAIL" || echo "OK"`
6. `test -d audio/fillers/tool_use && echo "FAIL" || echo "OK"`
7. `test -d audio/fillers/nonverbal && echo "OK" || echo "FAIL: nonverbal missing"`
8. `ls audio/fillers/` shows only `nonverbal/` and `pool.json`
  </verify>
  <done>
Personality prompt updated to describe non-verbal fillers instead of verbal acknowledgments. generate_fillers.py deleted. Old verbal clip directories (acknowledge, thinking, tool_use) deleted. audio/fillers/ contains only nonverbal/ directory and pool.json.
  </done>
</task>

</tasks>

<verification>
1. `grep -c "ollama\|aiohttp\|smart_filler\|FILLER_TOOL\|FILLER_THINKING\|_spoken_filler\|_classify_filler" live_session.py` returns 0
2. `grep -c "nonverbal" live_session.py` returns at least 3 (load, pick, pick)
3. `grep -c "_spawn_clip_factory" live_session.py` returns at least 2 (definition + call)
4. `python -c "import live_session"` succeeds
5. `test ! -f generate_fillers.py` (deleted)
6. `ls audio/fillers/` shows only nonverbal/ and pool.json
7. Personality prompt references non-verbal sounds, not "Got it" or "Sure thing"
</verification>

<success_criteria>
- Zero Ollama/LLM filler code remains in the codebase
- Filler system loads and plays exclusively from nonverbal/ directory
- Clip factory daemon spawns at session start (learner.py pattern)
- Personality prompt correctly describes non-verbal fillers
- All deprecated files and directories removed
- live_session.py imports cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/04-filler-system-overhaul/04-02-SUMMARY.md`
</output>
