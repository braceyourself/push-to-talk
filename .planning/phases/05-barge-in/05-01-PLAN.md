---
phase: 05-barge-in
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - live_session.py
  - pipeline_frames.py
autonomous: true

must_haves:
  truths:
    - "Microphone stays physically live (not muted via pactl) during AI playback"
    - "VAD detects sustained user speech (~0.5s) during AI playback"
    - "Detection triggers playback fade-out (~150ms linear ramp) and cancels queued audio"
    - "A trailing non-verbal filler clip plays after the fade to simulate natural interruption"
    - "A ~1.5s cooldown prevents rapid-fire re-triggers after a barge-in"
  artifacts:
    - path: "live_session.py"
      provides: "STT gating, VAD-in-STT detection, fade-out, cooldown, barge-in trigger"
      contains: "_stt_gated"
    - path: "pipeline_frames.py"
      provides: "BARGE_IN frame type for signaling interruptions"
      contains: "BARGE_IN"
  key_links:
    - from: "_stt_stage"
      to: "_trigger_barge_in"
      via: "VAD sustained speech counter reaches threshold while _stt_gated and playing_audio"
      pattern: "_trigger_barge_in"
    - from: "_trigger_barge_in"
      to: "_playback_stage"
      via: "generation_id increment causes playback to discard stale frames"
      pattern: "generation_id"
    - from: "_playback_stage"
      to: "stream.write"
      via: "linear fade applied to final audio chunk before stopping"
      pattern: "fade"
---

<objective>
Implement the core barge-in mechanism: replace mic muting with STT gating so the mic stays live during playback, run VAD on incoming audio in the STT stage to detect sustained user speech, and trigger a smooth playback interruption with fade-out, trailing filler clip, and cooldown.

Purpose: This is the foundational mechanism for BARGE-01, BARGE-02, and BARGE-03 — the user can interrupt AI mid-speech by speaking, VAD detects it, and playback cancels smoothly.
Output: Modified `live_session.py` with working barge-in detection and interruption, plus a new `BARGE_IN` frame type.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-barge-in/05-CONTEXT.md
@.planning/phases/05-barge-in/05-RESEARCH.md
@live_session.py
@pipeline_frames.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace mic muting with STT gating and wire VAD into STT stage</name>
  <files>live_session.py, pipeline_frames.py</files>
  <action>
**pipeline_frames.py:** Add `BARGE_IN = auto()` to `FrameType` enum (after FILLER, before CONTROL).

**live_session.py — STT gating flag:**
- Add `self._stt_gated = False` in `__init__` (near `self.playing_audio`)
- Add VAD state for barge-in detection:
  - `self._vad_speech_count = 0` (consecutive VAD-positive frame counter)
  - `self._barge_in_cooldown_until = 0` (timestamp)

**live_session.py — Replace mic mute with STT gate during playback:**

In `_llm_stage()` (Stage 3), where it currently calls `self._mute_mic()` after END_OF_UTTERANCE:
- KEEP the `self._mute_mic()` call here — this is when the user STOPS speaking and the LLM starts thinking. Mic mute during "thinking" is correct (no barge-in needed yet, AI isn't speaking).

In `_playback_stage()` (Stage 5):
- Where it currently calls `self._mute_mic()` on first audio chunk (`if not self.playing_audio`): Replace `self._mute_mic()` with `self._stt_gated = True`. The mic stays physically live.
- Where it currently calls `self._unmute_mic()` in `delayed_unmute()`: Replace with `self._stt_gated = False` (and keep `self._unmute_mic()` ONLY for the `self.muted` path — actually, remove the pactl unmute here since we're not muting during playback anymore, BUT we still need to unmute from the _llm_stage mute. So: keep `self._unmute_mic()` in `delayed_unmute` to undo the _llm_stage's mute.

**live_session.py — Load VAD model at session start:**
In `run()`, after spawning clip factory, add:
```python
if self.barge_in_enabled:
    self._load_vad_model()
```
Remove the `_load_vad_model()` call from `_vad_monitor_stage()` (it will be loaded once at startup instead).

**live_session.py — VAD detection in STT stage:**
In `_stt_stage()`, where it currently checks `if self.playing_audio or self.muted:` and clears the buffer:
- Change to: `if self.muted:` → clear buffer, continue (muted = user pressed mute, ignore everything)
- Add a NEW branch: `if self._stt_gated:` → instead of discarding, run VAD on the audio chunk:

```python
if self._stt_gated:
    # During AI playback: run VAD to detect barge-in speech
    audio_buffer.clear()
    silence_start = None
    has_speech = False
    speech_chunk_count = 0
    if self.barge_in_enabled and self._vad_model and self.playing_audio:
        if time.time() < self._barge_in_cooldown_until:
            continue
        prob = self._run_vad(frame.data)
        if prob > 0.5:
            self._vad_speech_count += 1
            # ~0.5s sustained speech: 4096 bytes at 24kHz 16-bit = ~85ms per chunk
            # 0.5s / 0.085s ≈ 6 chunks
            if self._vad_speech_count >= 6:
                print(f"Barge-in: Sustained speech detected ({self._vad_speech_count} chunks, prob={prob:.2f})", flush=True)
                await self._trigger_barge_in()
        else:
            self._vad_speech_count = 0
    continue
```

**live_session.py — Remove _vad_monitor_stage:**
Delete the `_vad_monitor_stage()` method entirely (it's a TODO stub). Remove it from the `stages` list in `run()`. Remove the `if self.barge_in_enabled: stages.append(self._vad_monitor_stage())` block.

**live_session.py — Reset VAD state:**
Add `self._vad_speech_count = 0` reset in `_check_interrupt()` method, after `self._interrupt_requested = False`.
Also reset VAD state (h, c tensors) after barge-in triggers — add a `_reset_vad_state()` helper that sets h and c back to zeros.
  </action>
  <verify>
1. `grep -n "_stt_gated" live_session.py` shows the flag being set/cleared in playback stage
2. `grep -n "_run_vad" live_session.py` shows VAD being called in the STT stage
3. `grep -n "_vad_monitor_stage" live_session.py` returns nothing (removed)
4. `grep -n "BARGE_IN" pipeline_frames.py` shows the new frame type
5. `python3 -c "from pipeline_frames import FrameType; print(FrameType.BARGE_IN)"` succeeds
  </verify>
  <done>Mic stays physically live during playback (STT gating instead of pactl mute). VAD runs on every audio chunk during playback in the STT stage. After 6 consecutive positive chunks (~0.5s), _trigger_barge_in is called.</done>
</task>

<task type="auto">
  <name>Task 2: Implement barge-in trigger with fade-out, trailing filler, and cooldown</name>
  <files>live_session.py</files>
  <action>
**live_session.py — Add `_trigger_barge_in()` method** (after `_check_interrupt`):

```python
async def _trigger_barge_in(self):
    """Barge-in detected: fade out playback, play trailing filler, reset state."""
    import numpy as np

    print("Barge-in: Triggering interruption", flush=True)

    # 1. Increment generation_id to discard all queued frames
    self.generation_id += 1

    # 2. Drain audio_out and llm_out queues (stale frames)
    for q in (self._audio_out_q, self._llm_out_q):
        while not q.empty():
            try:
                q.get_nowait()
            except asyncio.QueueEmpty:
                break

    # 3. Cancel filler if running
    if self._filler_cancel and not self._filler_cancel.is_set():
        self._filler_cancel.set()

    # 4. Set cooldown (1.5s)
    self._barge_in_cooldown_until = time.time() + 1.5

    # 5. Reset VAD speech counter and state
    self._vad_speech_count = 0
    self._reset_vad_state()

    # 6. Transition state
    self.playing_audio = False
    self._stt_gated = False

    # 7. Unmute mic (undo the _llm_stage mute from thinking phase)
    self._unmute_mic()

    # 8. Play a trailing non-verbal filler clip for naturalness
    if self.fillers_enabled:
        clip = self._pick_filler("nonverbal")
        if clip:
            # Play directly without going through generation_id checks
            # (we just incremented it, so use the new one)
            gen_id = self.generation_id
            # Only queue the first ~150ms worth of clip for a brief trail
            trail_bytes = int(SAMPLE_RATE * BYTES_PER_SAMPLE * 0.15)
            trail = clip[:trail_bytes] if len(clip) > trail_bytes else clip
            # Apply fade-out to the trail
            samples = np.frombuffer(trail, dtype=np.int16).copy()
            if len(samples) > 0:
                fade = np.linspace(0.8, 0.0, len(samples))
                samples = (samples.astype(np.float64) * fade).astype(np.int16)
                await self._audio_out_q.put(PipelineFrame(
                    type=FrameType.FILLER,
                    generation_id=gen_id,
                    data=samples.tobytes()
                ))

    # 9. Set status to listening
    self._set_status("listening")

    # Log it
    self._log_event("barge_in")
    print("Barge-in: Interruption complete, listening for user", flush=True)
```

**live_session.py — Add `_reset_vad_state()` helper:**
```python
def _reset_vad_state(self):
    """Reset VAD hidden state to avoid contamination between segments."""
    if self._vad_state:
        import numpy as np
        self._vad_state['h'] = np.zeros((2, 1, 64), dtype=np.float32)
        self._vad_state['c'] = np.zeros((2, 1, 64), dtype=np.float32)
```

**live_session.py — Playback stage: apply fade to last chunk before barge-in:**

In `_playback_stage()`, when writing TTS_AUDIO frames, wrap the `stream.write` call to detect barge-in mid-write. Before writing each chunk, check if `generation_id` changed (which `_trigger_barge_in` does):

Actually, the simpler approach: `_trigger_barge_in` already increments `generation_id` and drains queues. The playback loop's existing `if frame.generation_id != self.generation_id: continue` check will discard all subsequent frames. The stream.write call that's currently in-flight (in the executor) will complete its current chunk, which is fine — that's just one chunk (~85ms). The trailing filler clip with fade handles the smooth audio transition.

So no changes needed in `_playback_stage` for fade — the trailing filler clip IS the fade.

**live_session.py — Playback stage: handle BARGE_IN frame type:**
Not needed — barge-in is handled by generation_id increment, not by sending a frame. The BARGE_IN frame type is reserved for future use (e.g., signaling other stages).

**live_session.py — Cancel pending delayed_unmute on barge-in:**
In `_trigger_barge_in()`, also cancel the pending unmute task:
```python
if self._unmute_task and not self._unmute_task.done():
    self._unmute_task.cancel()
```
  </action>
  <verify>
1. `grep -n "_trigger_barge_in" live_session.py` shows the method definition and call site
2. `grep -n "_barge_in_cooldown_until" live_session.py` shows cooldown being set and checked
3. `grep -n "_reset_vad_state" live_session.py` shows the helper exists
4. `grep -n "barge_in" live_session.py` shows log event
5. `python3 -c "import live_session; print('OK')"` — module imports without error
  </verify>
  <done>Barge-in trigger increments generation_id (discards all stale frames), drains queues, plays a brief faded trailing filler clip for naturalness, sets 1.5s cooldown, resets VAD state, unmutes mic, and transitions to "listening" status.</done>
</task>

</tasks>

<verification>
1. Module imports: `python3 -c "from live_session import LiveSession; from pipeline_frames import FrameType; print(FrameType.BARGE_IN)"`
2. STT gating: Verify `_stt_gated` is set to True when playback starts and False when it ends or barge-in triggers
3. VAD in STT: Verify `_run_vad` is called inside `_stt_stage` when `_stt_gated` is True
4. No `_vad_monitor_stage`: Verify the stub is completely removed
5. Barge-in trigger: `_trigger_barge_in` method exists with generation_id increment, queue drain, cooldown, filler, state reset
6. Mic stays live: `_mute_mic` is NOT called in `_playback_stage` — only `_stt_gated = True`
</verification>

<success_criteria>
- Mic is not muted via pactl during AI playback (only during "thinking" phase between user speech and LLM response)
- VAD runs on audio chunks in the STT stage during playback
- After ~0.5s of sustained speech, barge-in triggers
- Playback stops with a brief faded trailing filler clip
- 1.5s cooldown prevents re-trigger
- All existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/05-barge-in/05-01-SUMMARY.md`
</output>
