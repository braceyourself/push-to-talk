---
phase: 05-barge-in
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - live_session.py
  - pipeline_frames.py
autonomous: true

must_haves:
  truths:
    - "Microphone stays physically live (not muted via pactl) during AI playback"
    - "VAD detects sustained user speech (~0.5s) during AI playback"
    - "Detection triggers playback fade-out (~150ms linear ramp) and cancels queued audio"
    - "A trailing non-verbal filler clip plays after the fade to simulate natural interruption"
    - "A ~1.5s cooldown prevents rapid-fire re-triggers after a barge-in"
    - "After barge-in ends (or playback ends naturally), STT silence tracking state is reset so the first post-ungating audio is handled cleanly"
  artifacts:
    - path: "live_session.py"
      provides: "STT gating, VAD-in-STT detection, fade-out, cooldown, barge-in trigger"
      contains: "_stt_gated"
    - path: "pipeline_frames.py"
      provides: "BARGE_IN frame type for signaling interruptions"
      contains: "BARGE_IN"
  key_links:
    - from: "_stt_stage"
      to: "_trigger_barge_in"
      via: "VAD sustained speech counter reaches threshold while _stt_gated and playing_audio"
      pattern: "_trigger_barge_in"
    - from: "_trigger_barge_in"
      to: "_playback_stage"
      via: "generation_id increment causes playback to discard stale frames"
      pattern: "generation_id"
    - from: "_playback_stage"
      to: "stream.write"
      via: "linear fade applied to final audio chunk before stopping"
      pattern: "fade"
    - from: "run()"
      to: "_load_vad_model"
      via: "VAD model loaded once at session start in run(), before stages spawn"
      pattern: "_load_vad_model"
    - from: "_stt_stage"
      to: "silence_start reset"
      via: "Tracks _was_stt_gated to detect gated->ungated transition and reset silence tracking"
      pattern: "_was_stt_gated"
---

<objective>
Implement the core barge-in mechanism: replace mic muting with STT gating so the mic stays live during playback, run VAD on incoming audio in the STT stage to detect sustained user speech, and trigger a smooth playback interruption with fade-out, trailing filler clip, and cooldown.

Purpose: This is the foundational mechanism for BARGE-01, BARGE-02, and BARGE-03 — the user can interrupt AI mid-speech by speaking, VAD detects it, and playback cancels smoothly.
Output: Modified `live_session.py` with working barge-in detection and interruption, plus a new `BARGE_IN` frame type.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-barge-in/05-CONTEXT.md
@.planning/phases/05-barge-in/05-RESEARCH.md
@live_session.py
@pipeline_frames.py
</context>

<tasks>

<task type="auto">
  <name>Task 1a: Replace mic muting with STT gating in playback stage</name>
  <files>live_session.py, pipeline_frames.py</files>
  <action>
**pipeline_frames.py:** Add `BARGE_IN = auto()` to `FrameType` enum (after FILLER, before CONTROL).

**live_session.py — STT gating flag in `__init__` (near `self.playing_audio` around line 93):**
- Add `self._stt_gated = False`
- Add `self._was_stt_gated = False` (tracks previous state for transition detection in STT stage)
- Add VAD state for barge-in detection:
  - `self._vad_speech_count = 0` (consecutive VAD-positive frame counter)
  - `self._barge_in_cooldown_until = 0` (timestamp)

**live_session.py — Keep mic mute in `_llm_stage()` (Stage 3, line ~1409):**
The `self._mute_mic()` after END_OF_UTTERANCE stays as-is. This is when the user STOPS speaking and the LLM starts thinking. Mic mute during "thinking" is correct.

**live_session.py — Replace mic mute with STT gate in `_playback_stage()` (Stage 5):**

At line ~1593-1596, where it currently does:
```python
if not self.playing_audio:
    self.playing_audio = True
    self._set_status("speaking")
    self._mute_mic()
```
Replace `self._mute_mic()` with `self._stt_gated = True`. The mic stays physically live so VAD can hear speech.

At line ~1564-1573, in the `delayed_unmute()` closure:
```python
async def delayed_unmute():
    await asyncio.sleep(0.5)
    if self.playing_audio:
        self.playing_audio = False
        self._unmute_mic()
        ...
```
Add `self._stt_gated = False` before `self._unmute_mic()`. Keep `self._unmute_mic()` because it undoes the _llm_stage's mute from the thinking phase.
  </action>
  <verify>
1. `grep -n "_stt_gated" live_session.py` shows the flag in __init__, set to True in playback start, set to False in delayed_unmute and trigger
2. `grep -n "BARGE_IN" pipeline_frames.py` shows the new frame type
3. `python3 -c "from pipeline_frames import FrameType; print(FrameType.BARGE_IN)"` succeeds
4. In `_playback_stage`, the `if not self.playing_audio:` block does NOT call `_mute_mic()`
  </verify>
  <done>Mic stays physically live during AI playback (STT gating via `_stt_gated = True` instead of pactl mute). `_stt_gated` is cleared on natural playback end (delayed_unmute) and on barge-in. BARGE_IN frame type exists in pipeline_frames.py.</done>
</task>

<task type="auto">
  <name>Task 1b: Wire VAD detection into STT stage, handle gated->ungated transition, remove monitor stub</name>
  <files>live_session.py</files>
  <action>
**live_session.py — Load VAD model at session start:**

In `run()` (line ~1685), after `self._spawn_clip_factory()`, add:
```python
if self.barge_in_enabled:
    self._load_vad_model()
```
This loads the model once at startup instead of inside the now-removed `_vad_monitor_stage()`.

**live_session.py — Remove `_vad_monitor_stage()` entirely:**
1. Delete the `_vad_monitor_stage()` method (lines ~662-680)
2. In `run()` (lines ~1714-1715), remove the block:
   ```python
   if self.barge_in_enabled:
       stages.append(self._vad_monitor_stage())
   ```

**live_session.py — VAD detection in `_stt_stage()` with gated->ungated transition handling:**

In `_stt_stage()`, the current code at line ~1329 is:
```python
# Ignore audio during playback or when user-muted
if self.playing_audio or self.muted:
    audio_buffer.clear()
    silence_start = None
    has_speech = False
    speech_chunk_count = 0
    continue
```

Replace that entire block with three separate branches:

```python
# Branch 1: User pressed mute — discard everything
if self.muted:
    audio_buffer.clear()
    silence_start = None
    has_speech = False
    speech_chunk_count = 0
    self._was_stt_gated = self._stt_gated
    continue

# Branch 2: STT gated (AI playback) — run VAD but don't transcribe
if self._stt_gated:
    # Clear transcription state (we're not accumulating for transcription)
    audio_buffer.clear()
    silence_start = None
    has_speech = False
    speech_chunk_count = 0
    self._was_stt_gated = True

    # Run VAD to detect barge-in speech
    if self.barge_in_enabled and self._vad_model and self.playing_audio:
        if time.time() < self._barge_in_cooldown_until:
            continue
        prob = self._run_vad(frame.data)
        if prob > 0.5:
            self._vad_speech_count += 1
            # ~0.5s sustained speech: 4096 bytes at 24kHz 16-bit = ~85ms per chunk
            # 0.5s / 0.085s ~ 6 chunks
            if self._vad_speech_count >= 6:
                print(f"Barge-in: Sustained speech detected ({self._vad_speech_count} chunks, prob={prob:.2f})", flush=True)
                await self._trigger_barge_in()
        else:
            self._vad_speech_count = 0
    continue

# Branch 3: Gated->ungated transition — reset silence tracking for clean start
if self._was_stt_gated:
    self._was_stt_gated = False
    audio_buffer.clear()
    silence_start = None
    has_speech = False
    speech_chunk_count = 0
    peak_rms = 0.0
    # Don't continue — fall through to normal audio processing below
```

The key insight: Branch 3 runs exactly once when `_stt_gated` transitions from True to False. It resets ALL silence tracking state so the first audio chunk after ungating starts fresh. Without this, stale `silence_start` or `has_speech` values from before the gate could cause the STT stage to immediately trigger a transcription on the first chunk (if silence_start was old) or miss valid speech.

After Branch 3, execution falls through to the normal audio processing code (line ~1336 onward: `audio_buffer.extend(frame.data)`, RMS check, silence detection).

**live_session.py — Reset VAD state in `_check_interrupt()`:**
In `_check_interrupt()` (line ~1641), after `self._interrupt_requested = False`, add:
```python
self._vad_speech_count = 0
```

**live_session.py — Add `_reset_vad_state()` helper** (after `_run_vad`, around line ~661):
```python
def _reset_vad_state(self):
    """Reset VAD hidden state to avoid contamination between segments."""
    if self._vad_state:
        import numpy as np
        self._vad_state['h'] = np.zeros((2, 1, 64), dtype=np.float32)
        self._vad_state['c'] = np.zeros((2, 1, 64), dtype=np.float32)
```
  </action>
  <verify>
1. `grep -n "_run_vad" live_session.py` shows VAD being called inside `_stt_stage` within the `_stt_gated` branch
2. `grep -n "_vad_monitor_stage" live_session.py` returns nothing (removed)
3. `grep -n "_was_stt_gated" live_session.py` shows the transition detection flag in __init__ and _stt_stage
4. `grep -n "_reset_vad_state" live_session.py` shows the helper method exists
5. `grep -n "_load_vad_model" live_session.py` shows it called in `run()` and NOT in `_vad_monitor_stage`
6. `python3 -c "import live_session; print('OK')"` — module imports without error
  </verify>
  <done>VAD runs on every audio chunk during AI playback in the STT stage. After 6 consecutive positive chunks (~0.5s), `_trigger_barge_in` is called. When `_stt_gated` transitions from True to False, all silence tracking state (silence_start, has_speech, speech_chunk_count, audio_buffer, peak_rms) is reset for a clean start. The VAD model loads once in `run()`. The `_vad_monitor_stage` stub is fully removed.</done>
</task>

<task type="auto">
  <name>Task 2: Implement barge-in trigger with fade-out, trailing filler, and cooldown</name>
  <files>live_session.py</files>
  <action>
**live_session.py — Add `_trigger_barge_in()` method** (after `_check_interrupt`):

```python
async def _trigger_barge_in(self):
    """Barge-in detected: fade out playback, play trailing filler, reset state."""
    import numpy as np

    print("Barge-in: Triggering interruption", flush=True)

    # 1. Cancel pending delayed_unmute task
    if self._unmute_task and not self._unmute_task.done():
        self._unmute_task.cancel()

    # 2. Increment generation_id to discard all queued frames
    self.generation_id += 1

    # 3. Drain audio_out and llm_out queues (stale frames)
    for q in (self._audio_out_q, self._llm_out_q):
        while not q.empty():
            try:
                q.get_nowait()
            except asyncio.QueueEmpty:
                break

    # 4. Cancel filler if running
    if self._filler_cancel and not self._filler_cancel.is_set():
        self._filler_cancel.set()

    # 5. Set cooldown (1.5s)
    self._barge_in_cooldown_until = time.time() + 1.5

    # 6. Reset VAD speech counter and state
    self._vad_speech_count = 0
    self._reset_vad_state()

    # 7. Transition state — ungating triggers _was_stt_gated reset in STT stage
    self.playing_audio = False
    self._stt_gated = False

    # 8. Unmute mic (undo the _llm_stage mute from thinking phase)
    self._unmute_mic()

    # 9. Play a trailing non-verbal filler clip for naturalness
    if self.fillers_enabled:
        clip = self._pick_filler("nonverbal")
        if clip:
            gen_id = self.generation_id
            # Only queue the first ~150ms worth of clip for a brief trail
            trail_bytes = int(SAMPLE_RATE * BYTES_PER_SAMPLE * 0.15)
            trail = clip[:trail_bytes] if len(clip) > trail_bytes else clip
            # Apply fade-out to the trail
            samples = np.frombuffer(trail, dtype=np.int16).copy()
            if len(samples) > 0:
                fade = np.linspace(0.8, 0.0, len(samples))
                samples = (samples.astype(np.float64) * fade).astype(np.int16)
                await self._audio_out_q.put(PipelineFrame(
                    type=FrameType.FILLER,
                    generation_id=gen_id,
                    data=samples.tobytes()
                ))

    # 10. Set status to listening
    self._set_status("listening")

    # Log it
    self._log_event("barge_in")
    print("Barge-in: Interruption complete, listening for user", flush=True)
```

**live_session.py — Add `_reset_vad_state()` helper** (if not already added in Task 1b):
```python
def _reset_vad_state(self):
    """Reset VAD hidden state to avoid contamination between segments."""
    if self._vad_state:
        import numpy as np
        self._vad_state['h'] = np.zeros((2, 1, 64), dtype=np.float32)
        self._vad_state['c'] = np.zeros((2, 1, 64), dtype=np.float32)
```

**Playback stage — no changes needed for fade:**
`_trigger_barge_in` increments `generation_id` and drains queues. The playback loop's existing `if frame.generation_id != self.generation_id: continue` check discards all subsequent frames. The stream.write in-flight completes its current chunk (~85ms), which is acceptable. The trailing filler clip with fade IS the smooth audio transition.

**BARGE_IN frame type:** Reserved for future use (e.g., signaling other stages). Barge-in is handled by generation_id increment, not by frame passing.
  </action>
  <verify>
1. `grep -n "_trigger_barge_in" live_session.py` shows the method definition and call site in _stt_stage
2. `grep -n "_barge_in_cooldown_until" live_session.py` shows cooldown being set and checked
3. `grep -n "_reset_vad_state" live_session.py` shows the helper exists
4. `grep -n "barge_in" live_session.py` shows log event
5. `grep -n "_unmute_task" live_session.py` shows cancellation in _trigger_barge_in
6. `python3 -c "import live_session; print('OK')"` — module imports without error
  </verify>
  <done>Barge-in trigger cancels pending delayed_unmute, increments generation_id (discards all stale frames), drains queues, plays a brief faded trailing filler clip for naturalness, sets 1.5s cooldown, resets VAD state, unmutes mic, and transitions to "listening" status. STT stage will detect the gated->ungated transition and reset its silence tracking.</done>
</task>

</tasks>

<verification>
1. Module imports: `python3 -c "from live_session import LiveSession; from pipeline_frames import FrameType; print(FrameType.BARGE_IN)"`
2. STT gating: Verify `_stt_gated` is set to True when playback starts and False when it ends or barge-in triggers
3. Gated->ungated transition: Verify `_was_stt_gated` is tracked and triggers silence state reset in `_stt_stage`
4. VAD in STT: Verify `_run_vad` is called inside `_stt_stage` when `_stt_gated` is True
5. VAD model loading: Verify `_load_vad_model` is called in `run()`, NOT in a monitor stage
6. No `_vad_monitor_stage`: Verify the stub is completely removed
7. Barge-in trigger: `_trigger_barge_in` method exists with generation_id increment, queue drain, delayed_unmute cancellation, cooldown, filler, state reset
8. Mic stays live: `_mute_mic` is NOT called in `_playback_stage` — only `_stt_gated = True`
</verification>

<success_criteria>
- Mic is not muted via pactl during AI playback (only during "thinking" phase between user speech and LLM response)
- VAD runs on audio chunks in the STT stage during playback
- After ~0.5s of sustained speech, barge-in triggers
- Playback stops with a brief faded trailing filler clip
- 1.5s cooldown prevents re-trigger
- When _stt_gated transitions from True to False (barge-in or natural end), STT silence tracking state is fully reset
- All existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/05-barge-in/05-01-SUMMARY.md`
</output>
