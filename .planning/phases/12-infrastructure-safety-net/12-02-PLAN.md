---
phase: 12-infrastructure-safety-net
plan: 02
type: tdd
wave: 1
depends_on: []
files_modified:
  - transcript_buffer.py
  - test_live_session.py
autonomous: true

must_haves:
  truths:
    - "Transcript buffer holds ~5 minutes of segments and older entries drop off automatically"
    - "Hallucination filter rejects known Whisper hallucination phrases with >95% accuracy"
    - "Buffer provides formatted context string suitable for LLM consumption"
    - "Short/single-word segments with elevated no_speech_prob are filtered"
  artifacts:
    - path: "transcript_buffer.py"
      provides: "TranscriptSegment dataclass, TranscriptBuffer ring buffer, is_hallucination filter"
      contains: "class TranscriptBuffer"
      exports: ["TranscriptSegment", "TranscriptBuffer", "is_hallucination", "HALLUCINATION_PHRASES"]
  key_links:
    - from: "transcript_buffer.py"
      to: "collections.deque"
      via: "stdlib bounded deque for ring buffer"
      pattern: "deque\\(maxlen="
---

<objective>
Build the TranscriptBuffer (bounded ring buffer for transcript segments) and expanded hallucination filter as independently testable modules.

Purpose: The transcript buffer is the output of the continuous STT pipeline and the input to Phase 13's decision engine. The hallucination filter is critical for ambient audio -- without it, continuous capture produces 40%+ hallucinated segments from keyboard typing, HVAC, and room tone.

Output: transcript_buffer.py with TranscriptSegment, TranscriptBuffer, and is_hallucination(). Full TDD test suite.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-infrastructure-safety-net/12-RESEARCH.md (TranscriptBuffer code example, hallucination phrase list, is_hallucination function)
@.planning/phases/12-infrastructure-safety-net/12-CONTEXT.md
@live_session.py (lines 2193-2207 for existing hallucination filter pattern)
@test_live_session.py (test patterns)
</context>

<feature>
  <name>TranscriptBuffer and Hallucination Filter</name>
  <files>transcript_buffer.py, test_live_session.py</files>
  <behavior>
  **TranscriptSegment dataclass:**
  - Fields: text (str), timestamp (float), confidence (float, default 1.0), source (str, default "user"), no_speech_prob (float, default 0.0)
  - source values: "user", "ai", "filtered", "other"

  **TranscriptBuffer:**
  - __init__(max_segments=200, max_age_seconds=300.0): bounded ring buffer
  - append(segment): adds segment, evicts old entries beyond max_age
  - get_context(max_tokens=2048) -> str: returns most recent segments formatted as "[source] text" lines, working backward from newest, limited to ~max_tokens*4 characters
  - get_since(timestamp) -> list[TranscriptSegment]: returns all segments after given timestamp
  - __len__() -> int: returns current segment count
  - clear(): empties the buffer
  - Thread-safe for concurrent append/read (Lock around time-based eviction)

  Cases:
  - append 5 segments -> len() returns 5
  - append with max_segments=3, add 5 segments -> len() returns 3, oldest 2 dropped
  - append segments with timestamps, wait until max_age passed -> get_context() returns empty (time eviction)
  - get_context() with 3 segments -> returns "[user] text1\n[user] text2\n[user] text3"
  - get_context(max_tokens=10) -> returns only the most recent segment(s) that fit
  - get_since(timestamp) -> returns only segments after that timestamp
  - clear() -> len() returns 0

  **is_hallucination(text, no_speech_prob=0.0) -> bool:**
  - Exact phrase match against expanded HALLUCINATION_PHRASES set (30+ phrases from research)
  - Case-insensitive, strips trailing punctuation
  - Single word with no_speech_prob > 0.3 -> True
  - Very short text (<=2 chars) -> True
  - Repetitive content (4+ words, <=2 unique) -> True
  - Normal speech -> False

  Cases:
  - "thank you" -> True (known phrase)
  - "Thanks for watching." -> True (case-insensitive, punctuation stripped)
  - "PLEASE SUBSCRIBE" -> True
  - "the" with no_speech_prob=0.5 -> True (single word + high no_speech_prob)
  - "hello" with no_speech_prob=0.1 -> False (single word but low no_speech_prob)
  - "hello" with no_speech_prob=0.0 -> False (not in hallucination list)
  - "a" -> True (<=2 chars)
  - "" -> True (empty after strip)
  - "thank you thank you thank you thank you" -> True (repetitive)
  - "I need help with my project" -> False (normal speech)
  - "What time is the meeting?" -> False (normal speech)
  - "subtitles by" -> True (known hallucination)
  </behavior>
  <implementation>
  Create transcript_buffer.py following the code examples from 12-RESEARCH.md:

  1. TranscriptSegment as a frozen dataclass with the fields above
  2. HALLUCINATION_PHRASES as a module-level frozenset with 30+ phrases (merge existing 18 from live_session.py line 2193 + research additions from 12-RESEARCH.md)
  3. is_hallucination() as a module-level function implementing the 4-layer check
  4. TranscriptBuffer class using collections.deque(maxlen=N) with threading.Lock for time-based eviction
  5. get_context() iterates in reverse, accumulates lines up to char budget, returns chronological order

  The module should have no external dependencies beyond stdlib. It must be importable independently of live_session.py.
  </implementation>
</feature>

<tasks>

<task type="auto">
  <name>Task 1: Write failing tests for TranscriptBuffer and hallucination filter (RED)</name>
  <files>test_live_session.py</files>
  <action>
  Add two new test sections to test_live_session.py following existing test patterns (@test decorator, run_test() function):

  **"Hallucination Filter Tests" section:**
  - test_hallucination_known_phrase: "thank you" -> True
  - test_hallucination_case_insensitive: "Thanks for watching." -> True (case + punctuation)
  - test_hallucination_subscribe: "PLEASE SUBSCRIBE" -> True
  - test_hallucination_single_word_high_nsp: "the" with no_speech_prob=0.5 -> True
  - test_hallucination_single_word_low_nsp: "hello" with no_speech_prob=0.1 -> False
  - test_hallucination_short_text: "a" -> True (<=2 chars)
  - test_hallucination_empty: "" -> True
  - test_hallucination_repetitive: "thank you thank you thank you thank you" -> True
  - test_hallucination_normal_speech: "I need help with my project" -> False
  - test_hallucination_normal_question: "What time is the meeting?" -> False
  - test_hallucination_subtitles: "subtitles by" -> True

  **"TranscriptBuffer Tests" section:**
  - test_buffer_append_and_len: append 5 segments -> len() returns 5
  - test_buffer_max_segments: max_segments=3, add 5 -> len() returns 3, oldest dropped
  - test_buffer_get_context_format: 3 segments -> "[user] text1\n[user] text2\n[user] text3"
  - test_buffer_get_context_max_tokens: max_tokens=10 -> only most recent segment(s) that fit
  - test_buffer_get_since: segments at different timestamps -> get_since returns correct subset
  - test_buffer_clear: add segments, clear() -> len() returns 0
  - test_buffer_time_eviction: segments with old timestamps, max_age_seconds=1 -> evicted on next append

  Run tests, confirm they fail (module does not exist yet).
  </action>
  <verify>`python3 test_live_session.py` -- new tests fail with ImportError (transcript_buffer.py doesn't exist yet). Existing tests still pass.</verify>
  <done>All hallucination filter and TranscriptBuffer tests written and confirmed failing.</done>
</task>

<task type="auto">
  <name>Task 2: Implement transcript_buffer.py to pass all tests (GREEN)</name>
  <files>transcript_buffer.py</files>
  <action>
  Create transcript_buffer.py following the code examples from 12-RESEARCH.md:

  1. TranscriptSegment as a frozen dataclass with fields: text, timestamp, confidence (default 1.0), source (default "user"), no_speech_prob (default 0.0)
  2. HALLUCINATION_PHRASES as module-level frozenset with 30+ phrases (merge existing 18 from live_session.py line 2193 + research additions)
  3. is_hallucination(text, no_speech_prob=0.0) -> bool: 4-layer check (exact phrase match, short text, single word + high nsp, repetitive)
  4. TranscriptBuffer class using collections.deque(maxlen=N) with threading.Lock for time-based eviction
  5. get_context() iterates in reverse, accumulates lines up to char budget, returns in chronological order

  No external dependencies beyond stdlib. Must be importable independently.

  Run full test suite, confirm all tests pass.
  </action>
  <verify>
  `python3 test_live_session.py` -- all tests pass including new TranscriptBuffer and hallucination filter tests.
  `python3 -c "from transcript_buffer import TranscriptBuffer, TranscriptSegment, is_hallucination; print('Import OK')"` -- imports cleanly.
  </verify>
  <done>transcript_buffer.py exists, all tests pass, module imports independently without errors.</done>
</task>

</tasks>

<verification>
Run `python3 test_live_session.py` -- all tests pass including new TranscriptBuffer and hallucination filter tests.
Run `python3 -c "from transcript_buffer import TranscriptBuffer, TranscriptSegment, is_hallucination; print('Import OK')"` -- imports cleanly.
</verification>

<success_criteria>
- transcript_buffer.py exists and imports without errors
- TranscriptBuffer handles count-based and time-based eviction correctly
- get_context() produces correctly formatted output for LLM consumption
- is_hallucination() catches all 30+ known phrases and the 4 detection layers work
- All tests pass in the full test suite
</success_criteria>

<output>
After completion, create `.planning/phases/12-infrastructure-safety-net/12-02-SUMMARY.md`
</output>
