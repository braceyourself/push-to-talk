---
phase: 12-infrastructure-safety-net
plan: 03
type: tdd
wave: 2
depends_on: ["12-01", "12-02"]
files_modified:
  - continuous_stt.py
  - live_session.py
  - test_live_session.py
autonomous: false

must_haves:
  truths:
    - "System captures and transcribes speech continuously without any button press"
    - "VAD gates what reaches Whisper -- silence and noise are not transcribed (NOTE: this VAD-gated approach supersedes the CONTEXT.md statement 'Whisper runs continuously (no VAD gating)'. Research showed ungated Whisper produces excessive hallucinations on ambient noise. VAD gating is the correct design.)"
    - "Transcript segments appear in the TranscriptBuffer with timestamps and source labels (NOTE: source='user' is a Phase 12 placeholder for all mic-captured segments. Speaker attribution — distinguishing user speech from other speakers — is deferred to Phase 13.)"
    - "Echo-cancelled audio source is used when available, graceful fallback to default mic"
    - "Whisper uses distil-large-v3 model instead of large-v3"
    - "Safety cap forces transcription after MAX_BUFFER_SECONDS regardless of silence"
    - "Resource stats (VRAM, Whisper latency, buffer depth) visible in terminal log"
  artifacts:
    - path: "continuous_stt.py"
      provides: "ContinuousSTT class: VAD-gated Whisper loop producing TranscriptSegments"
      contains: "class ContinuousSTT"
    - path: "live_session.py"
      provides: "Integration of ContinuousSTT, TranscriptBuffer, VRAMMonitor into pipeline"
      contains: "ContinuousSTT"
  key_links:
    - from: "continuous_stt.py"
      to: "transcript_buffer.py"
      via: "imports TranscriptSegment, TranscriptBuffer, is_hallucination"
      pattern: "from transcript_buffer import"
    - from: "continuous_stt.py"
      to: "vram_monitor.py"
      via: "imports VRAMMonitor for GPU health checks"
      pattern: "from vram_monitor import"
    - from: "live_session.py"
      to: "continuous_stt.py"
      via: "creates ContinuousSTT instance, runs as pipeline stage"
      pattern: "ContinuousSTT"
    - from: "continuous_stt.py"
      to: "pasimple"
      via: "records from echo-cancelled source (exact device name read from 12-01-SUMMARY.md)"
      pattern: "device_name.*"
---

<objective>
Build the ContinuousSTT module (VAD-gated Whisper loop) and integrate all Phase 12 components into the live session pipeline.

Purpose: This is the keystone plan -- it wires together VRAMMonitor (Plan 01), TranscriptBuffer + hallucination filter (Plan 02), PipeWire AEC (Plan 01), and the existing pipeline. After this plan, the system captures and transcribes speech continuously without any button press.

Output: continuous_stt.py module with tests, updated live_session.py with new pipeline stage, working always-on transcript stream.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-infrastructure-safety-net/12-RESEARCH.md (VAD-gated continuous STT skeleton, capture pattern)
@.planning/phases/12-infrastructure-safety-net/12-CONTEXT.md
@.planning/phases/12-infrastructure-safety-net/12-01-SUMMARY.md (VRAM measurements, AEC device name)
@.planning/phases/12-infrastructure-safety-net/12-02-SUMMARY.md (TranscriptBuffer and hallucination filter API)
@live_session.py (lines 1306-1391 for VAD, 1448-1506 for Whisper transcribe, 2020-2067 for capture, 2179-2380 for STT stage, 2845-2897 for pipeline setup)
@vram_monitor.py
@transcript_buffer.py
@pipeline_frames.py
@test_live_session.py
</context>

<feature>
  <name>ContinuousSTT and Pipeline Integration</name>
  <files>continuous_stt.py, live_session.py, test_live_session.py</files>
  <behavior>
  **ContinuousSTT class:**
  - __init__(transcript_buffer, vram_monitor=None, aec_device_name=None, on_segment=None, on_stats=None):
    - transcript_buffer: TranscriptBuffer instance to append segments to
    - vram_monitor: optional VRAMMonitor for health checks
    - aec_device_name: PipeWire AEC source name (None = default mic)
    - on_segment: callback(TranscriptSegment) for each new segment
    - on_stats: callback(dict) for periodic stats reporting
  - async start(): begins the continuous capture + VAD + transcription loop
  - stop(): signals the loop to exit gracefully
  - running (property): whether the loop is active
  - stats (property): returns dict with segment_count, hallucination_count, avg_latency_ms, buffer_depth, vram_level

  **Core loop behavior:**
  1. Audio capture thread records from AEC source (or default mic if unavailable) at 24kHz 16-bit mono
  2. Each chunk (~85ms) runs through Silero VAD (CPU, <1ms)
  3. If VAD probability > threshold (0.5): accumulate into speech buffer
  4. If silence exceeds 0.8s AND speech buffer has content: send to Whisper
  5. Whisper (distil-large-v3, int8_float16, GPU) transcribes in thread executor
  6. Result goes through is_hallucination() filter
  7. Clean segments appended to TranscriptBuffer as TranscriptSegment
  8. Safety cap: force transcription after 10s regardless of silence
  9. Stats emitted every 5 seconds (segment_count, hallucination_rate, vram_level, whisper_latency)

  **Key behaviors to test (mock-based, no GPU/mic required):**
  - Speech audio (VAD > 0.5) accumulates, silence triggers transcription
  - Non-speech audio (VAD < 0.5) does not accumulate
  - Safety cap fires after MAX_BUFFER_SECONDS even without silence
  - Hallucinated transcripts are filtered and not added to buffer
  - Clean transcripts are added to buffer with correct timestamp and source
  - AEC device fallback: if AEC source fails, falls back to default mic
  - Stats reporting includes segment_count, hallucination_count

  Cases:
  - 10 speech chunks + 10 silence chunks -> 1 transcription call, 1 segment in buffer
  - 10 speech chunks + Whisper returns "thank you" -> hallucination filtered, 0 segments
  - 120 continuous speech chunks (>10s) -> safety cap fires, transcription called
  - All silence chunks -> no transcription called
  - AEC device "Echo Cancellation Source" not available -> falls back to None (default)
  - Stats after 5 segments: segment_count=5, hallucination_count matches filtered count
  </behavior>
  <implementation>
  **Step 1: Write tests (RED)**

  Add "ContinuousSTT Tests" section to test_live_session.py. Mock:
  - pasimple.PaSimple (audio capture)
  - Silero VAD (onnxruntime InferenceSession)
  - faster_whisper.WhisperModel (Whisper transcription)
  - pynvml (VRAM monitoring)

  Test the core loop logic by feeding mock audio frames and checking TranscriptBuffer contents.

  **Step 2: Create continuous_stt.py (GREEN)**

  Build ContinuousSTT class following the skeleton from 12-RESEARCH.md:

  1. Audio capture thread pattern from live_session.py line 2044-2064:
     - pasimple.PaSimple with device_name=aec_device_name
     - Try AEC source first, fall back to None (default) if connection fails
     - Daemon thread reads CHUNK_SIZE bytes, puts PipelineFrame into asyncio.Queue

  2. VAD processing from live_session.py line 1333-1384:
     - Reuse existing _run_vad pattern (resample to 16kHz, 512-sample windows, Silero v5)
     - Load Silero VAD model from models/silero_vad.onnx
     - Track speech state: accumulate during speech, detect silence gap

  3. Whisper transcription from live_session.py line 1448-1506:
     - Load distil-large-v3 (NOT large-v3) with int8_float16
     - Run in thread executor (asyncio.get_event_loop().run_in_executor)
     - Multi-layer segment filtering (no_speech_prob, avg_logprob, compression_ratio)
     - Apply is_hallucination() from transcript_buffer.py as final filter

  4. Transcript output:
     - Append TranscriptSegment to the shared TranscriptBuffer
     - Call on_segment callback if provided
     - Print to terminal log: "STT [continuous]: {text}"

  5. Stats reporting:
     - Every 5 seconds, emit stats dict via on_stats callback
     - Include VRAM level from VRAMMonitor if available

  **Step 3: Integrate into live_session.py**

  Modify live_session.py to use ContinuousSTT:

  1. Add imports: `from continuous_stt import ContinuousSTT` and `from transcript_buffer import TranscriptBuffer, TranscriptSegment`
  2. In __init__ or start(): create TranscriptBuffer and ContinuousSTT instances
  3. In the pipeline stages list (line ~2887), add `self._continuous_stt.start()` as a new stage
  4. The existing _stt_stage() and _audio_capture_stage() remain for now (they handle the PTT-based flow which still works for dictation mode). ContinuousSTT runs alongside -- it will be the primary STT for always-on mode in Phase 14.
  5. Wire VRAMMonitor: create at startup, pass to ContinuousSTT, log stats periodically
  6. Wire AEC device name from Plan 01 SUMMARY (or config). Use the exact device name discovered during Plan 01. Add config option `aec_device_name` that defaults to "Echo Cancellation Source".
  7. Add periodic resource stats to terminal log: VRAM usage, Whisper latency, buffer depth (per CONTEXT.md: "Visible resource stats in terminal log")

  **IMPORTANT:** Do NOT remove or modify the existing PTT pipeline stages. ContinuousSTT runs as an ADDITIONAL parallel stage. The two modes will be reconciled in Phase 14.

  **Step 4: Run full test suite (GREEN)**

  `python3 test_live_session.py` -- all tests pass.
  </implementation>
</feature>

<tasks>

<task type="auto">
  <name>Task 1: ContinuousSTT module with TDD</name>
  <files>continuous_stt.py, test_live_session.py</files>
  <action>
  Follow the TDD cycle described in the implementation section above:
  1. Write failing tests in test_live_session.py (RED)
  2. Create continuous_stt.py to make tests pass (GREEN)
  3. Refactor if needed

  The module must be independently testable with mocked audio, VAD, and Whisper. It should import TranscriptBuffer, TranscriptSegment, and is_hallucination from transcript_buffer.py, and optionally VRAMMonitor from vram_monitor.py.

  Use distil-large-v3 model (NOT large-v3). This is a v2.0 decision from STATE.md.
  </action>
  <verify>
  `python3 test_live_session.py` -- all ContinuousSTT tests pass.
  `python3 -c "from continuous_stt import ContinuousSTT; print('Import OK')"` -- imports cleanly.
  </verify>
  <done>ContinuousSTT module exists with core loop logic, all tests pass, uses distil-large-v3.</done>
</task>

<task type="auto">
  <name>Task 2: Pipeline integration in live_session.py</name>
  <files>live_session.py, test_live_session.py</files>
  <action>
  Integrate ContinuousSTT, TranscriptBuffer, and VRAMMonitor into the live session pipeline:

  0. **Read the exact AEC device name from 12-01-SUMMARY.md** before proceeding. The AEC device name was discovered and recorded during Plan 01. Use that exact string as the `aec_device_name` value below -- do NOT assume it is "Echo Cancellation Source" (that was a config default placeholder). Open `.planning/phases/12-infrastructure-safety-net/12-01-SUMMARY.md` and find the documented device name string.

  1. Add imports at top of live_session.py:
     ```python
     from continuous_stt import ContinuousSTT
     from transcript_buffer import TranscriptBuffer, TranscriptSegment
     from vram_monitor import VRAMMonitor
     ```

  2. In LiveSession.__init__ (or appropriate setup):
     - Create self._transcript_buffer = TranscriptBuffer(max_segments=200, max_age_seconds=300.0)
     - Create self._vram_monitor = VRAMMonitor.create()  # Returns None if no GPU
     - Create self._continuous_stt = ContinuousSTT(
         transcript_buffer=self._transcript_buffer,
         vram_monitor=self._vram_monitor,
         aec_device_name=config.get("aec_device_name", "<exact name from 12-01-SUMMARY.md>"),
         on_segment=self._on_transcript_segment,
         on_stats=self._on_stt_stats,
       )

  3. Add callback methods:
     - _on_transcript_segment(segment): log to terminal, emit SSE event
     - _on_stt_stats(stats): log resource stats periodically

  4. Add continuous_stt.start() to the pipeline stages list (alongside existing stages, NOT replacing them)

  5. In stop/cleanup: call self._continuous_stt.stop(), self._vram_monitor.shutdown() if exists

  6. Ensure existing tests still pass -- the make_session() helper in test_live_session.py may need updating to mock the new imports.

  Do NOT remove existing _stt_stage() or _audio_capture_stage(). ContinuousSTT is additive.
  </action>
  <verify>
  `python3 test_live_session.py` -- ALL tests pass (existing + new).
  `python3 -c "from live_session import LiveSession; print('Import OK')"` -- imports without error.
  </verify>
  <done>
  LiveSession creates and runs ContinuousSTT alongside existing pipeline.
  TranscriptBuffer receives segments from continuous STT.
  VRAMMonitor reports resource stats.
  All existing tests continue to pass.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
  Complete Phase 12 infrastructure:
  - ContinuousSTT captures and transcribes speech continuously (no button press)
  - PipeWire AEC prevents the AI from hearing itself
  - TranscriptBuffer holds ~5 minutes of context with automatic eviction
  - Expanded hallucination filter (30+ phrases) keeps ambient noise out of transcripts
  - VRAMMonitor tracks GPU memory and enables proactive management
  - Resource stats visible in terminal log
  </what-built>
  <how-to-verify>
  1. Deploy the service: use the project's deploy mechanism to sync to ~/.local/share/push-to-talk/ and restart
  2. Start a live session and observe the terminal log
  3. Speak normally without pressing any button -- transcripts should appear in the log
  4. Play music or audio through speakers -- the transcript should NOT contain the music lyrics (AEC working)
  5. Be silent for 30 seconds while keyboard typing -- hallucination filter should prevent noise transcripts
  6. Check resource stats in the terminal log (VRAM usage, latency, buffer depth)
  7. Let it run for 5+ minutes -- verify buffer doesn't grow unbounded (stays at ~200 max segments or ~5 min)
  8. Run `python3 test_live_session.py` -- all tests pass
  </how-to-verify>
  <resume-signal>Type "approved" if continuous listening works cleanly, or describe issues</resume-signal>
</task>

</tasks>

<verification>
- All tests pass: `python3 test_live_session.py` exits with 0 failures
- ContinuousSTT imports cleanly: `python3 -c "from continuous_stt import ContinuousSTT"`
- TranscriptBuffer has segments after speaking: check via on_segment callback log
- Hallucination rate < 5% on ambient audio (measure during verification checkpoint)
- VRAM stays within budget during continuous operation
</verification>

<success_criteria>
- System captures and transcribes speech continuously without any button press
- AI speech does not appear in the transcript stream (AEC working)
- Transcript buffer holds ~5 minutes and older entries drop off
- Hallucination rate on ambient audio stays below 5%
- VRAM stays within budget (no OOM crashes)
- All tests pass (existing + new)
</success_criteria>

<output>
After completion, create `.planning/phases/12-infrastructure-safety-net/12-03-SUMMARY.md`
</output>
