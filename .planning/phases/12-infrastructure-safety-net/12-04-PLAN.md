---
phase: 12-infrastructure-safety-net
plan: 04
type: execute
wave: 2
depends_on: ["12-01", "12-02"]
files_modified:
  - live_session.py
  - test_live_session.py
autonomous: true

must_haves:
  truths:
    - "DeepgramSTT replaces ContinuousSTT in the pipeline -- same start/stop lifecycle"
    - "_stt_stage() consumes transcripts from DeepgramSTT via asyncio.Queue (not Whisper)"
    - "Playback/barge-in calls set_playing_audio on DeepgramSTT (not ContinuousSTT)"
    - "Echo fingerprints from _spoken_sentences are forwarded to DeepgramSTT"
    - "Existing pipeline tests still pass (LLM stage, composer, playback unchanged)"
    - "_stt_out_q receives END_OF_UTTERANCE + TRANSCRIPT frames from Deepgram path"
  artifacts:
    - path: "live_session.py"
      provides: "Rewritten _stt_stage, DeepgramSTT wiring in run(), updated playback hooks"
    - path: "test_live_session.py"
      provides: "Updated tests covering Deepgram STT integration"
  key_links:
    - from: "live_session.py"
      to: "deepgram_stt.py"
      via: "DeepgramSTT instantiation in run() and _stt_stage consuming transcript_q"
      pattern: "DeepgramSTT|_deepgram_stt|_deepgram_transcript_q"
    - from: "live_session.py _stt_stage"
      to: "live_session.py _llm_stage"
      via: "_stt_out_q with END_OF_UTTERANCE + TRANSCRIPT frames"
      pattern: "_stt_out_q\\.put"
    - from: "live_session.py _llm_stage"
      to: "deepgram_stt.py"
      via: "set_recent_ai_speech() called after each _spoken_sentences.append() (lines 1953, 1989, 2009)"
      pattern: "set_recent_ai_speech"
    - from: "live_session.py run()"
      to: "live_session.py _stt_whisper_fallback()"
      via: "on_unavailable callback triggers fallback when Deepgram exhausts reconnects"
      pattern: "_on_deepgram_unavailable"
---

<objective>
Integrate DeepgramSTT into live_session.py -- replace ContinuousSTT, rewrite _stt_stage, and update all playback/barge-in hooks.

Purpose: This is the central integration plan that wires DeepgramSTT into the existing pipeline. The _stt_stage() is rewritten from a Whisper batch-mode processor to a thin consumer of Deepgram transcript output. All references to ContinuousSTT are replaced with DeepgramSTT. Downstream stages (LLM, TTS, playback) remain unchanged.

Output: live_session.py uses DeepgramSTT instead of ContinuousSTT. Full pipeline works with Deepgram as the STT backend.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/research/ARCHITECTURE.md — Integration changes: __init__, run(), _stt_stage, playback hooks
@.planning/phases/12-infrastructure-safety-net/12-01-SUMMARY.md — DeepgramSTT class details
@live_session.py — Lines 32, 310, 1406-1517, 2190-2394, 2642-2643, 2674-2675, 2728-2729, 2788-2789, 2930-2938, 2951-2959, 2970-2971
@deepgram_stt.py — DeepgramSTT class (from Plan 01)
@test_live_session.py — Existing tests to keep passing
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace ContinuousSTT with DeepgramSTT in live_session.py</name>
  <files>live_session.py</files>
  <action>
Make these specific changes to live_session.py. Each change references exact line numbers from the current file.

**1. Update import (line 32):**
```python
# CHANGE:
from continuous_stt import ContinuousSTT
# TO:
from deepgram_stt import DeepgramSTT
```

**2. Update __init__ (line 310):**
```python
# CHANGE:
self._continuous_stt = None     # Created in run()
# TO:
self._deepgram_stt = None       # Created in run()
self._deepgram_transcript_q = None  # DeepgramSTT -> STT stage
```

**3. Update run() -- instantiation (lines 2930-2938):**
```python
# REMOVE the ContinuousSTT block and REPLACE with:
self._deepgram_transcript_q = asyncio.Queue(maxsize=50)
self._deepgram_stt = DeepgramSTT(
    api_key=self.deepgram_api_key,
    transcript_buffer=self._transcript_buffer,
    transcript_q=self._deepgram_transcript_q,
    aec_device_name=self.config.get("aec_device_name", "Echo Cancellation Source")
        if hasattr(self, 'config') and isinstance(getattr(self, 'config', None), dict)
        else "Echo Cancellation Source",
    on_segment=self._on_transcript_segment,
    on_stats=self._on_stt_stats,
    on_unavailable=self._on_deepgram_unavailable,
)
```

Also add the fallback switching method to LiveSession:
```python
def _on_deepgram_unavailable(self):
    """Called when DeepgramSTT exhausts reconnection attempts.

    Switches the pipeline to use local Whisper STT as fallback.
    """
    print("Live session: Deepgram unavailable, switching to Whisper fallback", flush=True)
    self._emit_event("stt_fallback", reason="deepgram_unavailable")
    # Launch Whisper fallback as a new asyncio task
    loop = asyncio.get_event_loop()
    loop.call_soon_threadsafe(
        lambda: asyncio.ensure_future(self._stt_whisper_fallback())
    )
```

**4. Update run() -- stages list (lines 2951-2959):**
```python
# CHANGE the last entry from:
self._continuous_stt.start(),  # Phase 12: always-on STT
# TO:
self._deepgram_stt.start(),    # Phase 12: Deepgram streaming STT
```

**5. Update run() -- cleanup (lines 2970-2971):**
```python
# CHANGE:
if self._continuous_stt:
    self._continuous_stt.stop()
# TO:
if self._deepgram_stt:
    self._deepgram_stt.stop()
```

**6. Update playback hooks (4 locations):**
Replace `self._continuous_stt.set_playing_audio(...)` with `self._deepgram_stt.set_playing_audio(...)` at:
- Line 2643: playback end
- Line 2675: playback start
- Line 2729: barge-in (set False)
- Line 2789: post barge-in (set False)

Add null checks: `if self._deepgram_stt:` before each call (same pattern as existing code).

**7. Wire echo fingerprints in _llm_stage where _spoken_sentences is populated:**
`_spoken_sentences` is populated in `_llm_stage()` at three locations (lines 1953, 1989, 2009) -- each after a `_spoken_sentences.append()` call. After EACH of these three append calls, add:
```python
if self._deepgram_stt and hasattr(self._deepgram_stt, 'set_recent_ai_speech'):
    self._deepgram_stt.set_recent_ai_speech(list(self._spoken_sentences))
```
This incrementally updates DeepgramSTT's echo fingerprints as each sentence is sent to TTS, so echo detection starts immediately for each sentence rather than waiting until the full turn is complete. Pass `list(...)` to copy the list and avoid mutation issues.

**8. Update _on_stt_stats callback (lines 2409-2421):**
Add handling for new stats keys from DeepgramSTT:
```python
if 'connected' in stats:
    parts.append(f"dg={'OK' if stats['connected'] else 'DOWN'}")
if 'reconnect_attempts' in stats:
    if stats['reconnect_attempts'] > 0:
        parts.append(f"reconn={stats['reconnect_attempts']}")
```

**9. DO NOT remove _stt_whisper_fallback or _whisper_transcribe yet.**
Keep them in the file for now -- they serve as fallback. They will be cleaned up in a future plan once Deepgram is proven stable. Just ensure they are no longer called in the main path.

**10. Update the pipeline print statement (line 2942):**
```python
# CHANGE:
print("Live session: Pipeline started (with StreamComposer + ContinuousSTT)", flush=True)
# TO:
print("Live session: Pipeline started (with StreamComposer + DeepgramSTT)", flush=True)
```
  </action>
  <verify>
  - `grep 'DeepgramSTT' live_session.py` shows import and instantiation
  - `grep 'ContinuousSTT' live_session.py` returns no results (fully replaced)
  - `grep '_deepgram_stt' live_session.py` shows all integration points
  - `grep 'on_unavailable' live_session.py` shows fallback callback wiring
  - `grep '_on_deepgram_unavailable' live_session.py` shows fallback method exists
  </verify>
  <done>live_session.py uses DeepgramSTT instead of ContinuousSTT at all integration points</done>
</task>

<task type="auto">
  <name>Task 2: Rewrite _stt_stage as Deepgram transcript consumer</name>
  <files>live_session.py</files>
  <action>
**Replace the entire _stt_stage method body (lines 2190-2394).**

The new _stt_stage is a thin consumer of DeepgramSTT output. It reads TranscriptSegment objects from `_deepgram_transcript_q` and emits END_OF_UTTERANCE + TRANSCRIPT pipeline frames to `_stt_out_q`.

```python
async def _stt_stage(self):
    """Consume DeepgramSTT transcripts and emit pipeline frames.

    Reads TranscriptSegment objects from _deepgram_transcript_q
    (populated by DeepgramSTT callbacks via loop.call_soon_threadsafe).
    Emits END_OF_UTTERANCE + TRANSCRIPT frames to _stt_out_q for the LLM stage.

    Handles:
    - muted: suppress when user mutes
    - _stt_gated: suppress during AI playback (VAD barge-in runs in DeepgramSTT)
    - _stt_flush_event: clear event (Deepgram handles flushing via speech_final)
    - generation_id: tag frames for interrupt coherence
    - _post_barge_in: reset after delivering post-barge-in transcript
    """
    print("STT: Using Deepgram streaming", flush=True)

    try:
        while self.running:
            try:
                segment = await asyncio.wait_for(
                    self._deepgram_transcript_q.get(), timeout=0.5
                )
            except asyncio.TimeoutError:
                # Check flush event during idle
                if self._stt_flush_event and self._stt_flush_event.is_set():
                    self._stt_flush_event.clear()
                    # Deepgram handles flushing via speech_final -- just clear the event
                continue

            # Gate checks
            if self.muted:
                continue
            if self._stt_gated:
                self._was_stt_gated = True
                continue

            # Gated -> ungated transition: discard first post-gate segment
            # (likely residual echo from AI playback)
            if self._was_stt_gated:
                self._was_stt_gated = False
                continue

            transcript = segment.text
            self._emit_event("stt_complete", text=transcript[:60],
                             latency_ms=0, rejected=False)
            print(f"STT [deepgram]: {transcript}", flush=True)

            await self._stt_out_q.put(PipelineFrame(
                type=FrameType.END_OF_UTTERANCE,
                generation_id=self.generation_id
            ))
            await self._stt_out_q.put(PipelineFrame(
                type=FrameType.TRANSCRIPT,
                generation_id=self.generation_id,
                data=transcript
            ))
            self._post_barge_in = False

    except Exception as e:
        print(f"STT stage error: {e}", flush=True)
```

**Key differences from old _stt_stage:**
- No audio processing (no numpy, no RMS, no silence detection)
- No Whisper transcription (no run_in_executor)
- No hallucination filter (handled by DeepgramSTT before queueing)
- No audio buffer management (handled by DeepgramSTT)
- Reads from `_deepgram_transcript_q` instead of `_audio_in_q`
- Same output: END_OF_UTTERANCE + TRANSCRIPT to `_stt_out_q`

**Preserve the barge-in VAD behavior:**
The old _stt_stage ran VAD for barge-in detection when `_stt_gated` was True. With DeepgramSTT, VAD runs inside DeepgramSTT continuously. Barge-in detection should still work via the existing `_run_vad` in the audio capture path. If barge-in VAD was only in _stt_stage, move it to a separate coroutine or ensure DeepgramSTT can signal barge-in. Check the `_audio_capture_stage` and barge-in logic to confirm.

Actually, reading the code more carefully: the barge-in VAD runs in `_stt_stage` lines 2272-2299 (Branch 2). This code reads audio frames from `_audio_in_q` and runs VAD when `_stt_gated`. Since the new _stt_stage no longer reads `_audio_in_q`, this barge-in detection must be preserved.

**Solution:** Keep a minimal audio consumer coroutine for barge-in VAD. Add a new `_barge_in_vad_stage()` coroutine that reads from `_audio_in_q` and only runs VAD for barge-in detection:

```python
async def _barge_in_vad_stage(self):
    """Run VAD on audio frames for barge-in detection during AI playback.

    This replaces the barge-in VAD logic that was embedded in the old
    _stt_stage. It reads audio frames and checks for sustained speech
    during AI playback to trigger barge-in.
    """
    if not self.barge_in_enabled:
        return

    try:
        while self.running:
            try:
                frame = self._audio_in_q.get_nowait()
            except asyncio.QueueEmpty:
                await asyncio.sleep(0.02)
                continue

            if frame.type != FrameType.AUDIO_RAW:
                continue

            # Only run VAD when AI is playing audio (barge-in detection)
            if not (self._stt_gated and self.playing_audio and self._vad_model):
                continue

            if time.time() < self._barge_in_cooldown_until:
                continue

            prob = self._run_vad(frame.data)
            if prob > 0.5:
                self._vad_speech_count += 1
                if self._vad_speech_count == 1:
                    self._set_status("listening")
                if self._vad_speech_count >= 6:
                    print(f"Barge-in: Sustained speech detected ({self._vad_speech_count} chunks, prob={prob:.2f})", flush=True)
                    await self._trigger_barge_in()
            else:
                if self._vad_speech_count > 0:
                    self._set_status("speaking")
                self._vad_speech_count = 0

    except Exception as e:
        print(f"Barge-in VAD error: {e}", flush=True)
```

Add this stage to the `stages` list in `run()`:
```python
stages = [
    self._audio_capture_stage(),
    self._stt_stage(),                 # Rewritten: Deepgram consumer
    self._barge_in_vad_stage(),        # NEW: barge-in VAD (was in old _stt_stage)
    self._llm_stage(),
    self._composer.run(),
    self._playback_stage(),
    interrupt_loop(),
    self._sse_server_stage(),
    self._deepgram_stt.start(),
]
```
  </action>
  <verify>
  - `grep '_stt_stage' live_session.py` shows the rewritten method
  - `grep '_barge_in_vad_stage' live_session.py` shows the new stage
  - `grep 'Whisper' live_session.py` in _stt_stage returns nothing (Whisper code removed from that method)
  - `python3 test_live_session.py` -- existing tests still pass
  - Dual audio capture note: DeepgramSTT runs its own pasimple capture thread while `_audio_capture_stage` also reads pasimple into `_audio_in_q` for `_barge_in_vad_stage`. Two pasimple readers from the same PipeWire source works correctly (PipeWire handles multiple client streams, confirmed in ARCHITECTURE.md line 664). During live testing, run `pw-top` and verify two `push-to-talk` capture streams appear simultaneously without errors.
  </verify>
  <done>_stt_stage consumes from _deepgram_transcript_q, barge-in VAD preserved in separate stage, existing tests pass, dual pasimple capture verified via pw-top</done>

</task>

</tasks>

<verification>
1. `python3 test_live_session.py` -- all existing tests pass
2. `grep 'ContinuousSTT' live_session.py` -- returns nothing (fully replaced)
3. `grep 'DeepgramSTT' live_session.py` -- shows import, instantiation, usage
4. `grep '_deepgram_transcript_q' live_session.py` -- shows queue creation and consumption
5. `grep '_barge_in_vad_stage' live_session.py` -- shows barge-in preservation
</verification>

<success_criteria>
live_session.py fully uses DeepgramSTT as the STT backend. The _stt_stage is a thin transcript consumer. Barge-in VAD is preserved in a separate stage. All existing tests pass. Downstream stages (LLM, TTS, playback) are unchanged.
</success_criteria>

<output>
After completion, create `.planning/phases/12-infrastructure-safety-net/12-04-SUMMARY.md`
</output>
