---
phase: 12-infrastructure-safety-net
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - deepgram_stt.py
  - test_deepgram_stt.py
autonomous: true

must_haves:
  truths:
    - "DeepgramSTT produces TranscriptSegment objects from Deepgram WebSocket events"
    - "VAD gates connection lifecycle (active/idle/sleep) -- not per-chunk audio filtering"
    - "KeepAlive messages are sent during silence to prevent 10-second timeout"
    - "Reconnection with exponential backoff handles WebSocket disconnections"
    - "is_final/speech_final accumulation pattern produces complete utterances"
    - "Hallucination filter rejects known artifacts before emitting segments"
  artifacts:
    - path: "deepgram_stt.py"
      provides: "DeepgramSTT class with same interface as ContinuousSTT"
      min_lines: 250
    - path: "test_deepgram_stt.py"
      provides: "Unit tests for DeepgramSTT with mock WebSocket"
      min_lines: 150
  key_links:
    - from: "deepgram_stt.py"
      to: "transcript_buffer.py"
      via: "TranscriptSegment creation and TranscriptBuffer.append()"
      pattern: "TranscriptBuffer\\.append"
    - from: "deepgram_stt.py"
      to: "deepgram-sdk"
      via: "DeepgramClient WebSocket connection"
      pattern: "DeepgramClient|LiveOptions"
---

<objective>
Create the DeepgramSTT class -- the core streaming STT component that replaces ContinuousSTT.

Purpose: This is the foundational component of Phase 12. DeepgramSTT manages the Deepgram Nova-3 WebSocket connection, Silero VAD for connection lifecycle, audio capture, transcript accumulation (is_final/speech_final pattern), and KeepAlive management. It produces TranscriptSegment objects with the same interface as ContinuousSTT (start/stop/set_playing_audio).

Output: Working `deepgram_stt.py` with comprehensive tests using a mock WebSocket server.
</objective>

<execution_context>
@/home/ethan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ethan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/ARCHITECTURE.md — DeepgramSTT class design, integration points, thread model
@.planning/research/STACK.md — Deepgram SDK API surface, LiveOptions, EventType
@.planning/research/PITFALLS.md — Pitfalls 1 (VAD gating), 2 (audio format), 3 (disconnection), 12 (KeepAlive)
@continuous_stt.py — Interface to replicate, VAD code to reuse, capture thread pattern
@transcript_buffer.py — TranscriptSegment, TranscriptBuffer, is_hallucination()
@pipeline_frames.py — FrameType enum (END_OF_UTTERANCE mapping)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write tests for DeepgramSTT</name>
  <files>test_deepgram_stt.py</files>
  <action>
Create `test_deepgram_stt.py` with tests that define DeepgramSTT behavior. Use mock objects for the Deepgram SDK (no real WebSocket connections).

**Test cases to write (RED phase -- all must fail initially):**

1. **test_transcript_accumulation_speech_final**: Simulate Deepgram `on_message` callbacks with is_final=True segments followed by speech_final=True. Verify accumulated text is joined and emitted as a single TranscriptSegment to TranscriptBuffer.

2. **test_interim_results_not_emitted**: Simulate interim results (is_final=False). Verify they do NOT produce TranscriptSegments -- only is_final segments are accumulated.

3. **test_speech_final_flushes_accumulated**: Send 3 is_final=True segments then 1 speech_final=True. Verify the flushed text is the join of all 3 accumulated finals.

4. **test_hallucination_rejected**: Send a speech_final with text matching hallucination phrases ("thank you", "thanks for watching"). Verify it is filtered and NOT appended to TranscriptBuffer.

5. **test_playback_suppression**: Set `set_playing_audio(True)`, send a valid speech_final. Verify transcript is suppressed (not emitted). Then `set_playing_audio(False)` and verify cooldown period also suppresses. After cooldown, verify transcripts flow again.

6. **test_keepalive_sent_on_silence**: Verify that when no audio is sent for KEEPALIVE_INTERVAL, the KeepAlive method is called on the connection mock.

7. **test_reconnection_on_error**: Simulate connection.send() raising an exception. Verify the connection state transitions to disconnected and reconnect attempt is made.

8. **test_transcript_queue_output**: Verify that when a transcript_q (asyncio.Queue) is provided, completed transcripts are put on the queue in addition to TranscriptBuffer.

9. **test_stats_property**: Verify the stats dict contains expected keys: segment_count, hallucination_count, avg_latency_ms, buffer_depth, connected, reconnect_attempts.

10. **test_empty_transcript_ignored**: Send is_final=True with empty transcript text. Verify nothing is emitted.

11. **test_on_unavailable_called_after_max_reconnects**: Set MAX_RECONNECT_ATTEMPTS low (e.g., 2). Simulate repeated connection failures. Verify the `on_unavailable` callback is invoked after attempts are exhausted.

**Mock strategy:**
- Mock `DeepgramClient` and its `listen.v1.connect()` to return a mock connection object
- Mock connection's `send()`, `keep_alive()`, `finish()`, `on()` methods
- Capture registered event handlers from `on()` calls and invoke them directly in tests
- Mock `pasimple` to avoid requiring audio hardware
- Use a real TranscriptBuffer (it has no external deps)

**Test file structure:**
```python
#!/usr/bin/env python3
"""Tests for DeepgramSTT streaming STT class."""
import asyncio
import time
from unittest.mock import MagicMock, patch, call
from transcript_buffer import TranscriptBuffer, TranscriptSegment

# Import DeepgramSTT once it exists
# Tests define expected behavior before implementation
```

Follow the project's existing test pattern (test_live_session.py): decorator-based test registration, global PASSED/FAILED counters, run_test() helper.
  </action>
  <verify>python3 test_deepgram_stt.py — all tests should FAIL (class does not exist yet) or show import errors</verify>
  <done>test_deepgram_stt.py exists with 11+ test cases defining DeepgramSTT behavior (including on_unavailable callback test)</done>
</task>

<task type="auto">
  <name>Task 2: Implement DeepgramSTT class</name>
  <files>deepgram_stt.py</files>
  <action>
Create `deepgram_stt.py` implementing the DeepgramSTT class to make all tests pass.

**Critical architecture decisions (from research -- do NOT deviate):**

1. **VAD role is CONNECTION LIFECYCLE, not per-chunk audio filtering.** (Pitfall 1)
   - When VAD detects speech: stream audio to Deepgram
   - When VAD detects extended silence (IDLE_TIMEOUT, ~10s): send KeepAlive instead of audio
   - When silence exceeds SLEEP_TIMEOUT (~60s): disconnect WebSocket entirely
   - When VAD detects speech after sleep: reconnect, buffer audio during reconnection
   - NEVER filter individual audio chunks based on VAD before sending to Deepgram

2. **Audio format: 24kHz 16-bit mono, no resampling.** (Pitfall 2)
   - Send raw PCM bytes from pasimple directly to `connection.send(audio_data)`
   - Explicitly set `encoding="linear16"`, `sample_rate=24000`, `channels=1` in LiveOptions
   - Only resample for Silero VAD (24kHz -> 16kHz, same as ContinuousSTT)

3. **Use Deepgram SDK sync client** (manages its own WebSocket thread)
   - `DeepgramClient(api_key)` -- NOT AsyncDeepgramClient
   - `client.listen.v1.connect(options)` returns connection object
   - `connection.on(EventType.MESSAGE, handler)` -- handler fires on SDK's internal thread
   - Use `loop.call_soon_threadsafe()` to bridge callbacks to asyncio

4. **Transcript accumulation pattern:**
   - `is_final=False` (interim): ignore for accumulation, optionally emit event for display
   - `is_final=True, speech_final=False` (final): accumulate text in `_accumulated_finals` list
   - `is_final=True, speech_final=True` (speech_final): join all accumulated finals, emit as TranscriptSegment, clear accumulator
   - Also handle `UtteranceEnd` event as secondary end-of-speech trigger (Pitfall 6)

5. **Connection lifecycle states:**
   - ACTIVE: streaming audio chunks to Deepgram
   - IDLE: sending KeepAlive every 5s (no audio billing)
   - SLEEP: WebSocket disconnected (zero cost)
   - Reconnection: exponential backoff (1s, 2s, 4s, ... 30s max), max 10 attempts

6. **Reuse from ContinuousSTT (copy and adapt):**
   - `_capture_thread()` -- pasimple audio capture (identical pattern)
   - `_resolve_device()` -- AEC device resolution (identical)
   - `_load_vad_model()` -- Silero ONNX loading (identical)
   - `_run_vad()` -- VAD inference with 24kHz->16kHz resampling (identical)

7. **Public interface (matches ContinuousSTT):**
   - `async start()` -- begin capture + streaming
   - `stop()` -- signal graceful shutdown
   - `set_playing_audio(playing)` -- playback suppression (suppress transcript output, keep streaming audio)
   - `running` property
   - `stats` property (with additional keys: connected, reconnect_attempts)

8. **Constructor parameters:**
   ```python
   def __init__(self, api_key, transcript_buffer, transcript_q=None,
                aec_device_name=None, on_segment=None, on_stats=None,
                on_unavailable=None):
   ```
   The `on_unavailable` callback is invoked when DeepgramSTT exhausts MAX_RECONNECT_ATTEMPTS and can no longer reach Deepgram. LiveSession uses this to switch to `_stt_whisper_fallback()`. Store the callback and call it at the point where reconnection gives up:
   ```python
   if self._reconnect_attempts >= MAX_RECONNECT_ATTEMPTS:
       print(f"DeepgramSTT: Exhausted {MAX_RECONNECT_ATTEMPTS} reconnect attempts", flush=True)
       if self._on_unavailable:
           self._on_unavailable()
       return  # Stop connection loop
   ```

**LiveOptions configuration:**
```python
LiveOptions(
    model="nova-3",
    language="en",
    encoding="linear16",
    sample_rate=24000,
    channels=1,
    interim_results=True,
    endpointing=300,
    utterance_end_ms="1000",
    smart_format=True,
    vad_events=True,
    punctuate=True,
)
```

**Threading model:**
- Audio capture thread (daemon, pasimple.read) -> `_audio_q` (asyncio.Queue, maxsize=200)
- Deepgram SDK internal WebSocket thread (managed by SDK, fires callbacks)
- Callbacks use `loop.call_soon_threadsafe()` to schedule on event loop
- Main coroutine `start()` runs `_connection_loop()` which manages lifecycle

**Key constants:**
```python
KEEPALIVE_INTERVAL = 5.0      # seconds between KeepAlive
IDLE_TIMEOUT = 10.0           # seconds of silence -> idle mode
SLEEP_TIMEOUT = 60.0          # seconds of idle -> disconnect
RECONNECT_DELAY_BASE = 1.0    # exponential backoff base
RECONNECT_MAX_DELAY = 30.0    # backoff cap
MAX_RECONNECT_ATTEMPTS = 10
PLAYBACK_COOLDOWN = 0.3       # seconds after TTS ends before accepting transcripts
```
  </action>
  <verify>python3 test_deepgram_stt.py — all tests pass</verify>
  <done>DeepgramSTT class exists in deepgram_stt.py, all test_deepgram_stt.py tests pass, class has same interface as ContinuousSTT</done>
</task>

</tasks>

<verification>
1. `python3 test_deepgram_stt.py` -- all tests pass
2. `python3 -c "from deepgram_stt import DeepgramSTT; print('Import OK')"` -- no import errors
3. DeepgramSTT has methods: start, stop, set_playing_audio, running (property), stats (property)
4. DeepgramSTT constructor accepts: api_key, transcript_buffer, transcript_q, aec_device_name, on_segment, on_stats
</verification>

<success_criteria>
DeepgramSTT class exists with full test coverage. It replicates ContinuousSTT's external interface while internally using Deepgram WebSocket streaming with proper VAD lifecycle management. Tests pass using mock WebSocket (no real Deepgram connection needed).
</success_criteria>

<output>
After completion, create `.planning/phases/12-infrastructure-safety-net/12-01-SUMMARY.md`
</output>
